{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Validation Wrapper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1W26M03hlr-YynanV8XRmWtv9bXxgIRw0",
      "authorship_tag": "ABX9TyM4s3V5J+vUoeYscFXHsH9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenneal/capstone-visual-neuroscience/blob/Dylan/Validation_Wrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMQyPTVxwhVU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbIj2QeEAbTE",
        "outputId": "56a9bc56-172e-4090-a148-e9cc2833f547"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrE1xeswQNHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afcce8e-339b-41f6-ff5d-573bf65bb510"
      },
      "source": [
        "# Install CaImAn - takes around 2 minutes\n",
        "\n",
        "!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "%cd '/content/CaImAn/'\n",
        "!pip install -e .\n",
        "\n",
        "# Install caiman dependencies (&> /dev/null will suppress the hundreds of printed lines in the output)\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "\n",
        "#import other dependencies\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "#IMPORTANT! Newer versions of h5py will cause errors when saving results\n",
        "!pip install h5py==2.10.0\n",
        "import h5py\n",
        "\n",
        "#Set up caiman\n",
        "!python setup.py build_ext -i\n",
        "\n",
        "#Other file setup\n",
        "!python caimanmanager.py install --inplace\n",
        "\n",
        "#Caiman imports\n",
        "import caiman as cm\n",
        "from caiman.motion_correction import MotionCorrect\n",
        "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "from caiman.utils.utils import download_demo\n",
        "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
        "from caiman.summary_images import local_correlations_movie_offline\n",
        "from scipy.ndimage import center_of_mass\n",
        "from IPython.display import display, clear_output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CaImAn'...\n",
            "remote: Enumerating objects: 24933, done.\u001b[K\n",
            "remote: Counting objects: 100% (868/868), done.\u001b[K\n",
            "remote: Compressing objects: 100% (432/432), done.\u001b[K\n",
            "remote: Total 24933 (delta 481), reused 753 (delta 419), pack-reused 24065\u001b[K\n",
            "Receiving objects: 100% (24933/24933), 518.57 MiB | 27.95 MiB/s, done.\n",
            "Resolving deltas: 100% (16694/16694), done.\n",
            "Checking out files: 100% (317/317), done.\n",
            "/content/CaImAn\n",
            "Obtaining file:///content/CaImAn\n",
            "Installing collected packages: caiman\n",
            "  Running setup.py develop for caiman\n",
            "Successfully installed caiman-1.9.7\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "running build_ext\n",
            "Installed /root/caiman_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCRFFvODsO4i"
      },
      "source": [
        "## Get paths to movie files and labelled ROI masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfNJcFmeEq23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493f75c0-259a-4fc0-b504-e3a0641b1b55"
      },
      "source": [
        "#get a list of our masks and a list of our stacks in the same order\n",
        "from os import listdir\n",
        "maskpath = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs'\n",
        "mask_filenames = [f for f in listdir(maskpath) if 'manualROIs' in f]\n",
        "mask_filenames = sorted(mask_filenames)\n",
        "mask_filenames"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['210728_0_1_manualROIs_tm2_tm9_syt.mat',\n",
              " '210731_0_1_manualROIs_mix2_syt.mat',\n",
              " '210815_0_1_manualROIs_mix1_syt.mat',\n",
              " '211023_0_1_manualROIs_tm2_tm4_syt.mat',\n",
              " '211106_0_1_manualROIs_tm1_t5_syt.mat',\n",
              " '211106_1_1_manualROIs_tm4_t5_syt.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBBLhWJoFMXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421a0e8a-74fa-4cbe-e394-c63e79723e32"
      },
      "source": [
        "stack_indices = [x[:10] for x in mask_filenames] #get the index portion of the masks\n",
        "stack_celltypes = [x[22:(len(x)-4)] for x in mask_filenames] #get the cell type descriptions\n",
        "\n",
        "#create filenames in mat and h5, well only keep what exists\n",
        "stack_filenames_h5 = ['CLEAN_' + stack_indices[x] + '_stackRaw_mc_' + stack_celltypes[x] \\\n",
        "                   + '_.h5' for x in range(len(mask_filenames))] #reconstruct filenames for the movies we have masks for\n",
        "stack_filenames_mat = ['CLEAN_' + stack_indices[x] + '_stackRaw_mc_' + stack_celltypes[x] \\\n",
        "                   + '_.mat' for x in range(len(mask_filenames))] #reconstruct filenames for the movies we have masks for\n",
        "stack_filenames = stack_filenames_h5 + stack_filenames_mat \n",
        "stack_filenames"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5',\n",
              " 'CLEAN_210731_0_1_stackRaw_mc_mix2_syt_.h5',\n",
              " 'CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5',\n",
              " 'CLEAN_211023_0_1_stackRaw_mc_tm2_tm4_syt_.h5',\n",
              " 'CLEAN_211106_0_1_stackRaw_mc_tm1_t5_syt_.h5',\n",
              " 'CLEAN_211106_1_1_stackRaw_mc_tm4_t5_syt_.h5',\n",
              " 'CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.mat',\n",
              " 'CLEAN_210731_0_1_stackRaw_mc_mix2_syt_.mat',\n",
              " 'CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.mat',\n",
              " 'CLEAN_211023_0_1_stackRaw_mc_tm2_tm4_syt_.mat',\n",
              " 'CLEAN_211106_0_1_stackRaw_mc_tm1_t5_syt_.mat',\n",
              " 'CLEAN_211106_1_1_stackRaw_mc_tm4_t5_syt_.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cRs3HHyG0nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cecd9a3a-0d35-4408-d609-d6d1623bbb3e"
      },
      "source": [
        "#checking that files exist in our cleaned file\n",
        "stackpath = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED'\n",
        "stackfiles = [f for f in listdir(stackpath) if f in stack_filenames]\n",
        "stackfiles = sorted(stackfiles)\n",
        "stackfiles"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5',\n",
              " 'CLEAN_210731_0_1_stackRaw_mc_mix2_syt_.h5',\n",
              " 'CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5',\n",
              " 'CLEAN_211023_0_1_stackRaw_mc_tm2_tm4_syt_.h5',\n",
              " 'CLEAN_211106_0_1_stackRaw_mc_tm1_t5_syt_.h5',\n",
              " 'CLEAN_211106_1_1_stackRaw_mc_tm4_t5_syt_.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkrZMX_oLZ8J"
      },
      "source": [
        "#convert filenames back into paths\n",
        "maskpaths = [maskpath+'/'+f for f in mask_filenames]\n",
        "stackpaths = [stackpath+'/'+f for f in stackfiles]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O3Ta8XtKXFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c2470f-fb3f-4906-d328-733b80a482d8"
      },
      "source": [
        "#join the lists into pairs of tuples\n",
        "mask_stack_pairs = list(map(lambda x, y:[x,y], maskpaths, stackpaths))\n",
        "mask_stack_pairs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210728_0_1_manualROIs_tm2_tm9_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5'],\n",
              " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210731_0_1_manualROIs_mix2_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210731_0_1_stackRaw_mc_mix2_syt_.h5'],\n",
              " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210815_0_1_manualROIs_mix1_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5'],\n",
              " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211023_0_1_manualROIs_tm2_tm4_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211023_0_1_stackRaw_mc_tm2_tm4_syt_.h5'],\n",
              " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211106_0_1_manualROIs_tm1_t5_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_0_1_stackRaw_mc_tm1_t5_syt_.h5'],\n",
              " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211106_1_1_manualROIs_tm4_t5_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_t5_syt_.h5']]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzmBKC4DsV2y"
      },
      "source": [
        "## Initialize parameters object with starter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24iRFksugPTv"
      },
      "source": [
        "#create parameters object\n",
        "opts = params.CNMFParams()\n",
        "#fname will be assigned in the loop\n",
        "fnames = []\n",
        "subfolder = 'stackRaw_mc'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLzfCy0wFb-g"
      },
      "source": [
        "# set initial values for extraction and evaluation\n",
        "# most of these are specific to our data and will not need to be changed during optimization\n",
        "\n",
        "# overall params about our data\n",
        "\n",
        "fr = 20                 # approximate frame rate of data - CONFIRMED FPS\n",
        "decay_time = .4         # length of transient - CONFIRMED APPROPRIATE FOR OUR INDICATOR GCaMP6f\n",
        "dims = [128, 256]       # dimensions of the FOV in pixels - CONFIRMED\n",
        "dxy = [.29, .29]        # resolution of 1 pixel in um - CONFIRMED BY CARL\n",
        "\n",
        "opts.set('data', {'fnames': fnames,\n",
        "                   'fr': fr,\n",
        "                   'decay_time': decay_time,\n",
        "                   'dims': dims,\n",
        "                   'dxy': dxy\n",
        "                  })\n",
        "\n",
        "\n",
        "# params related to the temporal traces\n",
        "\n",
        "p = 1                   # order of the autoregressive system - 0 from carl's code, probably should be 1\n",
        "fudge_factor = 1        # (default is 0.96; Carl's value = 1) -- bias correction factor for discrete time constants\n",
        "ITER = 5                # (default is 2; Carl's value=5) -- block coordinate descent iterations\n",
        "tnb = 2                  # temporal global background components - TUNE\n",
        "\n",
        "opts.set('temporal', {'p': p,\n",
        "                      'fudge_factor': fudge_factor,\n",
        "                      'ITER': ITER,\n",
        "                      'nb': tnb\n",
        "                 })\n",
        "\n",
        "# p is also set in the preprocessing step\n",
        "opts.set('preprocess', {'p': p\n",
        "                 })\n",
        "\n",
        "\n",
        "\n",
        "# params related to the FOV and patches for parallel processing\n",
        "\n",
        "is_patches = True      # flag for processing in patches or not - turn on or off\n",
        "\n",
        "if is_patches:          # PROCESS IN PATCHES AND THEN COMBINE \n",
        "    rf = 25             # half size of each patch -not tuned\n",
        "    stride = 5          # overlap between patches -not tuned\n",
        "    K = 3               # number of components in each patch - TUNE - gets set later in INIT params\n",
        "    p_patch = p\n",
        "\n",
        "else:                   # PROCESS THE WHOLE FOV AT ONCE\n",
        "    rf = None           # setting these parameters to None Not used\n",
        "    stride = None       # will run CNMF on the whole FOV not used\n",
        "    K = 20              # number of neurons expected (in the whole FOV) - not used\n",
        "\n",
        "n_processes = 2         # Number of processes to run in parallel, 2 for 2 cores available in Colab\n",
        "\n",
        "opts.set('patch', {'rf': rf,\n",
        "                   'stride': stride,\n",
        "                   'n_processes': n_processes,\n",
        "                   'p_patch': p_patch\n",
        "                  })   \n",
        "\n",
        "\n",
        "\n",
        "# initialization params\n",
        "ssub = 2                # spatial downsampling\n",
        "tsub = 2                # temporal downsampling\n",
        "ssub_B = 3              # background spatial downsampling\n",
        "gSig = [4,4]            # radius (half-size) of average neurons (in pixels)\n",
        "nb = 2                  # number of background components\n",
        "\n",
        "opts.set('init', {'K': K,            # declared above in patch params    \n",
        "                   'gSig': gSig,      \n",
        "                   'tsub': tsub,\n",
        "                   'ssub': ssub,\n",
        "                   'ssub_B': ssub_B,\n",
        "                   'nb': nb\n",
        "                  })\n",
        "\n",
        "# parameters related to merging correlated ROIs\n",
        "merge_thr = 0.9     # merging threshold, max correlation allowed - TUNE\n",
        "\n",
        "opts.set('merging', {'merge_thr': merge_thr\n",
        "                            })\n",
        "\n",
        "\n",
        "#set some spatial params\n",
        "snb = 2                  # spatial global background components - TUNE\n",
        "\n",
        "opts.set('spatial', {'nb': snb\n",
        "                            })\n",
        "\n",
        "# %% COMPONENT EVALUATION\n",
        "# the components are evaluated in three ways:\n",
        "#   a) the shape of each component must be correlated with the data\n",
        "#   b) a minimum peak SNR is required over the length of a transient\n",
        "#   c) each shape passes a CNN based classifier (this will pick up only neurons\n",
        "#           and filter out active processes)\n",
        "\n",
        "\n",
        "#Not sure if these should be tuned or not\n",
        "\n",
        "min_SNR = 2.5      # peak SNR for accepted components (if above this, acept)\n",
        "SNR_lowest = 1         # minimum SNR for accepted components (if below this, reject)\n",
        "rval_thr = 0.9     # space correlation threshold (if above this, accept)\n",
        "\n",
        "use_cnn = False      # use the CNN classifier affects if 2 below params are used\n",
        "min_cnn_thr = 0.9  # if cnn classifier predicts below this value, reject\n",
        "cnn_lowest = 0.1   # neurons with cnn probability lower than this value are rejected\n",
        "\n",
        "opts.set('quality', {'min_SNR': min_SNR,\n",
        "                     'SNR_lowest': SNR_lowest,\n",
        "                     'rval_thr': rval_thr,\n",
        "                     'use_cnn': use_cnn,\n",
        "                     'min_cnn_thr': min_cnn_thr,\n",
        "                     'cnn_lowest': cnn_lowest})\n",
        "\n",
        "\n",
        "#Manually assign subfolder variable\n",
        "opts.motion['var_name_hdf5'] = subfolder\n",
        "opts.data['var_name_hdf5'] = subfolder"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T37S56psacn"
      },
      "source": [
        "## Define pipeline function to run Caiman"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yT59EZk84XL"
      },
      "source": [
        "#Function to run cnmf, run seeded cnmf using masks, then return validation\n",
        "\n",
        "def score_params(path_to_stack, path_to_masks, opts):\n",
        "  import warnings\n",
        "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "  fnames = [path_to_stack]\n",
        "\n",
        "  try:\n",
        "\n",
        "    if 'dview' in locals():\n",
        "      cm.stop_server(dview=dview)\n",
        "    dview = cm.cluster.start_server(ncpus=2)\n",
        "\n",
        "    #Run CNMF on raw stack using passed params\n",
        "    #print('starting cnmf')\n",
        "    cnm = cnmf.CNMF(n_processes = 2, params=opts, dview=dview)\n",
        "    #print('cnm object initialized')\n",
        "    cnm = cnm.fit_file(motion_correct = False, include_eval=True)\n",
        "    #print('cnmf and component evaluation completed')\n",
        "\n",
        "\n",
        "    #Read in masks and reformat\n",
        "    g = h5py.File(path_to_masks, 'r')\n",
        "\n",
        "    #transpose the matrix and save to an array A\n",
        "    mask_A = g['bwMaskStack'][:].T\n",
        "\n",
        "    g.close()\n",
        "\n",
        "    #rearrange the dimensions and show the new shape\n",
        "    mask_A = mask_A.transpose(1,0,2)\n",
        "\n",
        "    #reshape to 2D, first dimension is 128*256 (32768), 2nd dimension is the # of ROI's\n",
        "    mask_A = mask_A.reshape((mask_A.shape[1]*mask_A.shape[0]), mask_A.shape[2])\n",
        "\n",
        "    #convert the values from 0/1 to boolean False/True\n",
        "    mask_A = np.array(mask_A, dtype=bool)\n",
        "    #print('mask read in and reformatted')\n",
        "\n",
        "    #Seeded CNMF only works when seeded using mmap\n",
        "    #import pathlib\n",
        "\n",
        "    #read data from the original cnmf's mmap location\n",
        "    Yr, dims, T = cm.load_memmap(cnm.mmap_file)\n",
        "\n",
        "    # load frames in python format (T x X x Y)\n",
        "    mov = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
        "    #print('movie matrix loaded for seeded cnmf')\n",
        "\n",
        "\n",
        "    #For seeded CNMF, need to adjust some params\n",
        "    opts.patch['only_init'] = False\n",
        "    opts.data['use_cnn'] = False\n",
        "\n",
        "    #print('params adjusted for seeded cnmf')\n",
        "    \n",
        "    #Initialize a new cnmf object and pass in our masks as the \"Ain\" param\n",
        "    #\"Ain\" is A-in, meaning the A matrix holding the spatial footprints of the roi's\n",
        "    cnm_seeded = cnmf.CNMF(n_processes = 2, params=opts, dview=None, Ain=mask_A)\n",
        "    #print('seeded cnmf object initialized')\n",
        "    cnm_seeded.fit(mov)\n",
        "    #print('seeded cnmf completed')\n",
        "\n",
        "    #Try running register_ROIs and see what happens\n",
        "    matched_ROIs1, matched_ROIs2, non_matched1, non_matched2, performance, A2 = cm.base.rois.register_ROIs(cnm_seeded.estimates.A, cnm.estimates.A, dims=dims)\n",
        "    #print('validation and scoring completed')\n",
        "\n",
        "    #restore params for the next regular cnmf iteration\n",
        "    opts.patch['only_init'] = True\n",
        "    #opts.data['use_cnn'] = True\n",
        "\n",
        "    cm.stop_server(dview=dview)\n",
        "\n",
        "\n",
        "    #return performance metrics\n",
        "    return {'matched_ROIs1': matched_ROIs1,\n",
        "            'matched_ROIs2': matched_ROIs2,\n",
        "            'non_matched1': non_matched1,\n",
        "            'non_matched2': non_matched2, \n",
        "            'performance': performance,\n",
        "            'A2': A2,\n",
        "            'cnm_estimates': cnm.estimates,\n",
        "            'seeded_cnm_estimates': cnm_seeded.estimates}\n",
        "\n",
        "  except:\n",
        "    print('failed')\n",
        "    cm.stop_server(dview=dview)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AT-5zoysj-B"
      },
      "source": [
        "## Function to score all our stacks and return the avg f1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJtcnIiCBWQb"
      },
      "source": [
        "#loop through the stack-mask pairs and print the accuracy results\n",
        "\n",
        "def score_all_stacks(all_params):\n",
        "\n",
        "  print(all_params)\n",
        "\n",
        "  K = all_params[0]\n",
        "  nb = all_params[1]\n",
        "  merge_thresh = all_params[2]\n",
        "  gSig = [all_params[3], all_params[4]] #param passes one value, recreate [x,y] structure\n",
        "  SNR_lowest = all_params[5]\n",
        "\n",
        "\n",
        "  from statistics import mean\n",
        "\n",
        "  #hard coded paths since these won't change for now, proceduralize later\n",
        "  mask_stack_pairs = [['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210728_0_1_manualROIs_tm2_tm9_syt.mat',\n",
        "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5'],\n",
        " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210731_0_1_manualROIs_mix2_syt.mat',\n",
        "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210731_0_1_stackRaw_mc_mix2_syt_.h5'],\n",
        " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210815_0_1_manualROIs_mix1_syt.mat',\n",
        "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5'],\n",
        " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211023_0_1_manualROIs_tm2_tm4_syt.mat',\n",
        "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211023_0_1_stackRaw_mc_tm2_tm4_syt_.h5'],\n",
        " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211106_0_1_manualROIs_tm1_t5_syt.mat',\n",
        "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_0_1_stackRaw_mc_tm1_t5_syt_.h5'],\n",
        " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211106_1_1_manualROIs_tm4_t5_syt.mat',\n",
        "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_t5_syt_.h5']]\n",
        "\n",
        "\n",
        "\n",
        "  #Assign params passed in by the wrapper function\n",
        "  opts.init['K'] = K\n",
        "  opts.init['nb'] = nb #nb gets assigned in three different dicts\n",
        "  opts.spatial['nb'] = nb\n",
        "  opts.temporal['nb'] = nb\n",
        "  opts.merging['merge_thresh'] = merge_thresh\n",
        "  opts.init['gSig'] = gSig\n",
        "\n",
        "  #store precisions from each stack-mask pair for this iteration in a list, we'll return the average\n",
        "  f1s = []\n",
        "\n",
        "  #this loop will run all stacks through caiman using a given set of parameters to get the accuracy\n",
        "  for pair in mask_stack_pairs:\n",
        "    path_to_stack = pair[1]\n",
        "    path_to_masks = pair[0]\n",
        "\n",
        "    #set fnames before calling caiman function\n",
        "    opts.data['fnames'] = [path_to_stack]\n",
        "    print(opts.data['fnames'])\n",
        "\n",
        "    results = score_params(path_to_stack=path_to_stack, \\\n",
        "              path_to_masks=path_to_masks, \\\n",
        "              opts=opts)\n",
        "    \n",
        "    #store this stack-mask pair's precision\n",
        "    #later handle some kind of logging to keep a dict of info returned\n",
        "    f1s.append(results['performance']['f1_score'])\n",
        "\n",
        "    print(results['performance'])\n",
        "\n",
        "  #return the mean precision for all mask-stack pairs\n",
        "  #negative of the precision, so that the optimizer can minimize\n",
        "  print(f1s)\n",
        "  return -mean(f1s)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb433-9AHs1s"
      },
      "source": [
        "## Bayesian Model Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRTllB4wHZIZ",
        "outputId": "6a3b303a-9e60-4e0e-a6b1-a3c2f5e6416a"
      },
      "source": [
        "!pip install scikit-optimize\n",
        "import skopt\n",
        "from skopt.callbacks import CheckpointSaver\n",
        "from skopt.callbacks import DeltaYStopper\n",
        "from skopt.callbacks import DeadlineStopper\n",
        "from skopt import plots\n",
        "from skopt import load"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 100 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.0.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6tFYAUmBPr0"
      },
      "source": [
        "# #load old checkpoints if we need - change path\n",
        "# checkpoints = skopt.load('../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/search_checkpoints2.pkl')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEmfHQiMSh07"
      },
      "source": [
        "#define the parameter space - this is the entirety of the space I want to explore and will take a long time to run\n",
        "\n",
        "#change params if needed\n",
        "SPACE = [\n",
        "        skopt.space.Integer(2, 8, name='K'), #number of ROIs to expect in the FOV\n",
        "        skopt.space.Integer(1,3, name='nb'), #measure of how much background noise to remove, minimum 2 but higher could remove ROIs\n",
        "        skopt.space.Real(.85, .99, name= 'merge_thresh'), #how correlated ROIs need to be before they get merged\n",
        "        skopt.space.Integer(5, 15, name = 'gSig_wid'), #half-width of neurons - Supposedly the most important\n",
        "        skopt.space.Integer(2, 10, name = 'gSig_hei'), #half-height of neurons - Supposedly the most important\n",
        "        skopt.space.Real(.5, 1.5, name = 'SNR_lowest')] #Minimum SNR accepted for ROIs, (if below this, reject)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCAv43maVVNO"
      },
      "source": [
        "#saves a checkpoint every iteration to this filepath\n",
        "\n",
        "#CHANGE THIS PATH OR FILENAME BEFORE YOU RUN THIS - LEAVE THE EXTENSION AS .PKL\n",
        "checkpoint_saver = CheckpointSaver('../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/search_checkpoints_dh_attempt_2.pkl')\n",
        "\n",
        "#stopping criteria - stop if the 5 best iterations are within 3% of each other- might want to make more strict\n",
        "stopping_criteria = skopt.callbacks.DeltaYStopper(.03, n_best=5)\n",
        "\n",
        "#second criteria, stop after 11.5 hours if it hasn't stopped yet - takes time in seconds as argument\n",
        "mins = 11.5 * 60\n",
        "seconds = mins * 60\n",
        "stopping_criteria_2 = DeadlineStopper(total_time= seconds)\n",
        "\n",
        "\n",
        "# surrogate function, directly pass in parameter list, returns precision result directly\n",
        "#this is the function that the optimizer minimizes\n",
        "#score_all_stacks returns the precision * -1 so that the optimizer can minimize it\n",
        "def objective(parameters):\n",
        "    return score_all_stacks(parameters)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGFUFobpS_Z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22c4ddaa-c5b3-40da-e11f-42e5fba00128"
      },
      "source": [
        "#optimizer using objective function, parameter space, checkpointer, stopping criteria\n",
        "\n",
        "#change minimizer function if needed\n",
        "results = skopt.gbrt_minimize(objective, \n",
        "                              SPACE, \n",
        "                              callback=[checkpoint_saver, stopping_criteria, stopping_criteria_2], \n",
        "                              initial_point_generator = 'halton',\n",
        "                              n_jobs = 2,\n",
        "                              verbose=True)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Evaluating function at random point.\n",
            "[2, 1, 0.85, 5, 2, 0.5]\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "............spatial support for each components given by the user\n",
            "{'recall': 0.0, 'precision': 0.0, 'accuracy': 0.0, 'f1_score': 0.0}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "............spatial support for each components given by the user\n",
            "{'recall': 0.06666666666666667, 'precision': 0.5, 'accuracy': 0.0625, 'f1_score': 0.11764705882352941}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "............spatial support for each components given by the user\n",
            "{'recall': 0.08333333333333333, 'precision': 0.5, 'accuracy': 0.07692307692307693, 'f1_score': 0.14285714285714285}\n",
            "[0.0, 0.11764705882352941, 0.14285714285714285]\n",
            "Iteration No: 1 ended. Evaluation done at random point.\n",
            "Time taken: 260.1534\n",
            "Function value obtained: -0.0868\n",
            "Current minimum: -0.0868\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "[5, 2, 0.878, 6, 3, 0.5769230769230769]\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "............spatial support for each components given by the user\n",
            "{'recall': 0.0, 'precision': 0.0, 'accuracy': 0.0, 'f1_score': 0.0}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "............spatial support for each components given by the user\n",
            "{'recall': 0.06666666666666667, 'precision': 0.2, 'accuracy': 0.05263157894736842, 'f1_score': 0.1}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "............spatial support for each components given by the user\n",
            "{'recall': 0.08333333333333333, 'precision': 0.2, 'accuracy': 0.0625, 'f1_score': 0.11764705882352941}\n",
            "[0.0, 0.1, 0.11764705882352941]\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 290.1464\n",
            "Function value obtained: -0.0725\n",
            "Current minimum: -0.0868\n",
            "Iteration No: 3 started. Evaluating function at random point.\n",
            "[4, 2, 0.906, 8, 3, 0.6538461538461539]\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "........failed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-9648849a4718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0minitial_point_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'halton'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                               verbose=True, )\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skopt/optimizer/gbrt.py\u001b[0m in \u001b[0;36mgbrt_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    185\u001b[0m                          \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                          \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sampling\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                          model_queue_size=model_queue_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-ec37b38ff3c5>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#score_all_stacks returns the precision * -1 so that the optimizer can minimize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore_all_stacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-acb402e7b3fe>\u001b[0m in \u001b[0;36mscore_all_stacks\u001b[0;34m(all_params)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m#store this stack-mask pair's precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#later handle some kind of logging to keep a dict of info returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mf1s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'performance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'performance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o51vLguAbVcW"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvhFGPKvLhiK"
      },
      "source": [
        "skopt.plots.plot_convergence(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9QJR1mbLbiM"
      },
      "source": [
        "skopt.plots.plot_objective(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt9VjwbVsvI7"
      },
      "source": [
        "## Old working code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcRf62puVu1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2e4058-cfdf-48c6-bc6e-4910bcf1eb3d"
      },
      "source": [
        "# #tests score_all_stacks directly\n",
        "# dummy_in = [13, 2, 0.9, 5, 10, .8]\n",
        "# score_all_stacks(dummy_in)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13, 2, 0.9, 5, 10, 0.8]\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "............spatial support for each components given by the user\n",
            "{'recall': 0.4166666666666667, 'precision': 0.026041666666666668, 'accuracy': 0.02512562814070352, 'f1_score': 0.049019607843137254}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210731_0_1_stackRaw_mc_mix2_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            ".............spatial support for each components given by the user\n",
            "{'recall': 0.14285714285714285, 'precision': 0.07692307692307693, 'accuracy': 0.05263157894736842, 'f1_score': 0.1}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "..................spatial support for each components given by the user\n",
            "{'recall': 0.13333333333333333, 'precision': 0.16666666666666666, 'accuracy': 0.08, 'f1_score': 0.14814814814814814}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211023_0_1_stackRaw_mc_tm2_tm4_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            ".............spatial support for each components given by the user\n",
            "{'recall': 0.0, 'precision': 0.0, 'accuracy': 0.0, 'f1_score': 0.0}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_0_1_stackRaw_mc_tm1_t5_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "........"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/CaImAn/caiman/summary_images.py:217: RuntimeWarning: invalid value encountered in true_divide\n",
            "  w_mov = (Y - np.mean(Y, axis=0)) / np.std(Y, axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....spatial support for each components given by the user\n",
            "{'recall': 0.0, 'precision': 0.0, 'accuracy': 0.0, 'f1_score': 0.0}\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_t5_syt_.h5']\n",
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "............spatial support for each components given by the user\n",
            "{'recall': 0.2, 'precision': 0.07692307692307693, 'accuracy': 0.058823529411764705, 'f1_score': 0.1111111111111111}\n",
            "[0.049019607843137254, 0.1, 0.14814814814814814, 0.0, 0.0, 0.1111111111111111]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.06804647785039941"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG6EVQNSdPr8",
        "outputId": "300a393c-027d-4ca6-afb1-76d04735a9ba"
      },
      "source": [
        "# #tests score_params directly\n",
        "# opts.data['fnames'] = ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.mat']\n",
        "# score_params(path_to_masks='../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210728_0_1_manualROIs_tm2_tm9_syt.mat', \\\n",
        "#               path_to_stack='../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.mat', \\\n",
        "#               opts=opts)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "........."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Loading a *.mat file. x- and y- dimensions might have been swapped.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed\n",
            "...."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugOP9IDygmWK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "4c2c7190-38e4-4d8d-8101-c516b38c366d"
      },
      "source": [
        "# #tests cnm directly\n",
        "# opts.quality['use_cnn'] = True\n",
        "# opts.data['fnames'] = ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.mat']\n",
        "\n",
        "# if 'dview' in locals():\n",
        "#     cm.stop_server(dview=dview)\n",
        "# dview = cm.cluster.start_server(ncpus=2)\n",
        "# cnm = cnmf.CNMF(n_processes=2, params=opts, dview=dview)\n",
        "# #print('cnm object initialized')\n",
        "# cnm = cnm.fit_file(motion_correct = False, include_eval=True)\n",
        "# cm.stop_server(dview=dview)\n",
        "\n",
        "# cnm.estimates.A"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "........"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Loading a *.mat file. x- and y- dimensions might have been swapped.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-335f09c13e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcnm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print('cnm object initialized')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcnm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotion_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CaImAn/caiman/source_extraction/cnmf/cnmf.py\u001b[0m in \u001b[0;36mfit_file\u001b[0;34m(self, motion_correct, indices, include_eval)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                                  border_to_0=b0)\n\u001b[1;32m    366\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0mfname_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_memmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0mYr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_memmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CaImAn/caiman/mmapping.py\u001b[0m in \u001b[0;36msave_memmap\u001b[0;34m(filenames, base_name, resize_fact, remove_init, idx_xy, order, var_name_hdf5, xy_shifts, is_3D, add_to_movie, border_to_0, dview, n_chunks, slices)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbasestring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                     \u001b[0mYr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaiman\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_relocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name_hdf5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_name_hdf5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                     \u001b[0mYr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CaImAn/caiman/base/movies.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file_name, fr, start_time, meta_data, subindices, shape, var_name_hdf5, in_memory, is_behavior, bottom, top, left, right, channel, outtype, is3D)\u001b[0m\n\u001b[1;32m   1507\u001b[0m                             'might have been swapped.')\n\u001b[1;32m   1508\u001b[0m             \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m             \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m                 \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/miobase.py\u001b[0m in \u001b[0;36mget_matfile_version\u001b[0;34m(fileobj)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaj_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown mat file type, version %s, %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown mat file type, version 0, 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCBKNW4psfBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2b8d4c-b8dc-418d-8b1c-c0843ec8a15d"
      },
      "source": [
        "# #tests masks and scoring directly \n",
        "# fnames = ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5']\n",
        "# path_to_masks='../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210728_0_1_manualROIs_tm2_tm9_syt.mat'\n",
        "# #Read in masks and reformat\n",
        "# g = h5py.File(path_to_masks, 'r')\n",
        "\n",
        "# #transpose the matrix and save to an array A\n",
        "# mask_A = g['bwMaskStack'][:].T\n",
        "\n",
        "# g.close()\n",
        "\n",
        "# #rearrange the dimensions and show the new shape\n",
        "# mask_A = mask_A.transpose(1,0,2)\n",
        "\n",
        "# #reshape to 2D, first dimension is 128*256 (32768), 2nd dimension is the # of ROI's\n",
        "# mask_A = mask_A.reshape((mask_A.shape[1]*mask_A.shape[0]), mask_A.shape[2])\n",
        "\n",
        "# #convert the values from 0/1 to boolean False/True\n",
        "# mask_A = np.array(mask_A, dtype=bool)\n",
        "# #print('mask read in and reformatted')\n",
        "\n",
        "# if 'dview' in locals():\n",
        "#     cm.stop_server(dview=dview)\n",
        "# dview = cm.cluster.start_server(ncpus=2)\n",
        "\n",
        "# #Seeded CNMF only works when seeded using mmap\n",
        "# #import pathlib\n",
        "\n",
        "# #create memmory map location for the original movie\n",
        "# #fname_new = cm.save_memmap(fnames, base_name=pathlib.Path(fnames[0]).stem + \"_memmap_\", order='C')\n",
        "\n",
        "# #read data from mmap location\n",
        "# Yr, dims, T = cm.load_memmap(cnm.mmap_file)\n",
        "\n",
        "# # load frames in python format (T x X x Y)\n",
        "# mov = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
        "# #print('movie matrix loaded for seeded cnmf')\n",
        "\n",
        "\n",
        "# #For seeded CNMF, need to adjust some params\n",
        "# opts.patch['only_init'] = False\n",
        "# opts.patch['rf'] = None\n",
        "# opts.data['use_cnn'] = False\n",
        "\n",
        "# #print('params adjusted for seeded cnmf')\n",
        "    \n",
        "# #Initialize a new cnmf object and pass in our masks as the \"Ain\" param\n",
        "# #\"Ain\" is A-in, meaning the A matrix holding the spatial footprints of the roi's\n",
        "# cnm_seeded = cnmf.CNMF(n_processes = 2, params=opts, dview=None, Ain=mask_A)\n",
        "# #print('seeded cnmf object initialized')\n",
        "# cnm_seeded.fit(mov)\n",
        "# #print('seeded cnmf completed')\n",
        "\n",
        "# #Try running register_ROIs and see what happens\n",
        "# matched_ROIs1, matched_ROIs2, non_matched1, non_matched2, performance, A2 = cm.base.rois.register_ROIs(cnm_seeded.estimates.A, cnm.estimates.A, dims=dims)\n",
        "# #print('validation and scoring completed')\n",
        "\n",
        "# performance"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "........spatial support for each components given by the user\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.06666666666666667,\n",
              " 'f1_score': 0.125,\n",
              " 'precision': 0.1,\n",
              " 'recall': 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}