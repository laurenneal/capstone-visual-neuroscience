{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Validation Wrapper.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fCRFFvODsO4i",
        "OzmBKC4DsV2y",
        "8T37S56psacn"
      ],
      "mount_file_id": "1W26M03hlr-YynanV8XRmWtv9bXxgIRw0",
      "authorship_tag": "ABX9TyOkTeyAxXRc36j7xgFqthQF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenneal/capstone-visual-neuroscience/blob/Dylan/Validation_Wrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMQyPTVxwhVU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbIj2QeEAbTE",
        "outputId": "16cfaab9-eb51-46fb-c73a-7ec61809f57b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrE1xeswQNHM",
        "outputId": "38e04e3b-07aa-4653-f07e-d63972fd9dd5"
      },
      "source": [
        "# Install CaImAn - takes around 2 minutes\n",
        "\n",
        "!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "%cd '/content/CaImAn/'\n",
        "!pip install -e .\n",
        "\n",
        "# Install caiman dependencies (&> /dev/null will suppress the hundreds of printed lines in the output)\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "\n",
        "#import other dependencies\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "#IMPORTANT! Newer versions of h5py will cause errors when saving results\n",
        "!pip install h5py==2.10.0\n",
        "import h5py\n",
        "\n",
        "#Set up caiman\n",
        "!python setup.py build_ext -i\n",
        "\n",
        "#Other file setup\n",
        "!python caimanmanager.py install --inplace\n",
        "\n",
        "#Caiman imports\n",
        "import caiman as cm\n",
        "from caiman.motion_correction import MotionCorrect\n",
        "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "from caiman.utils.utils import download_demo\n",
        "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
        "from caiman.summary_images import local_correlations_movie_offline\n",
        "from scipy.ndimage import center_of_mass\n",
        "from IPython.display import display, clear_output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CaImAn'...\n",
            "remote: Enumerating objects: 24916, done.\u001b[K\n",
            "remote: Counting objects: 100% (851/851), done.\u001b[K\n",
            "remote: Compressing objects: 100% (421/421), done.\u001b[K\n",
            "remote: Total 24916 (delta 475), reused 739 (delta 414), pack-reused 24065\u001b[K\n",
            "Receiving objects: 100% (24916/24916), 518.52 MiB | 29.09 MiB/s, done.\n",
            "Resolving deltas: 100% (16688/16688), done.\n",
            "Checking out files: 100% (317/317), done.\n",
            "/content/CaImAn\n",
            "Obtaining file:///content/CaImAn\n",
            "Installing collected packages: caiman\n",
            "  Running setup.py develop for caiman\n",
            "Successfully installed caiman-1.9.6\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "running build_ext\n",
            "Installed /root/caiman_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCRFFvODsO4i"
      },
      "source": [
        "## Get paths to movie files and labelled ROI masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfNJcFmeEq23",
        "outputId": "5866d042-f6fe-4d06-f148-f4e1ab528de6"
      },
      "source": [
        "#get a list of our masks and a list of our stacks in the same order\n",
        "from os import listdir\n",
        "maskpath = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs'\n",
        "mask_filenames = [f for f in listdir(maskpath) if 'CLEAN' not in f and '.ipynb' not in f]\n",
        "mask_filenames"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['210815_0_1_manualROIs_mix1_syt.mat',\n",
              " '211106_1_1_manualROIs_tm4_syt.mat',\n",
              " '211023_0_1_manualROIs_tm2_tm4_syt.mat',\n",
              " '210731_0_1_manualROIs_t5_syt.mat',\n",
              " '210728_0_1_manualROIs_tm2_tm9_syt.mat',\n",
              " '211106_0_1_manualROIs_tm1_syt.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBBLhWJoFMXP",
        "outputId": "0f80d5de-c479-4882-a1e6-c56d23499b2f"
      },
      "source": [
        "stack_indices = [x[:10] for x in mask_filenames] #get the index portion of the masks\n",
        "stack_celltypes = [x[22:(len(x)-4)] for x in mask_filenames] #get the cell type descriptions\n",
        "stack_filenames = ['CLEAN_' + stack_indices[x] + '_stackRaw_mc_' + stack_celltypes[x] \\\n",
        "                   + '_.h5' for x in range(len(mask_filenames))] #reconstruct filenames for the movies we have masks for\n",
        "stack_filenames"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5',\n",
              " 'CLEAN_211106_1_1_stackRaw_mc_tm4_syt_.h5',\n",
              " 'CLEAN_211023_0_1_stackRaw_mc_tm2_tm4_syt_.h5',\n",
              " 'CLEAN_210731_0_1_stackRaw_mc_t5_syt_.h5',\n",
              " 'CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5',\n",
              " 'CLEAN_211106_0_1_stackRaw_mc_tm1_syt_.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cRs3HHyG0nV",
        "outputId": "b44f6650-e8be-4236-a561-390616751b83"
      },
      "source": [
        "#checking that files exist in our cleaned file - only 2 do\n",
        "stackpath = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED'\n",
        "stackfiles = [f for f in listdir(stackpath) if f in stack_filenames]\n",
        "stackfiles"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CLEAN_211106_1_1_stackRaw_mc_tm4_syt_.h5',\n",
              " 'CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5',\n",
              " 'CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkrZMX_oLZ8J"
      },
      "source": [
        "#convert filenames back into paths\n",
        "maskpaths = [maskpath+'/'+f for f in mask_filenames]\n",
        "stackpaths = [stackpath+'/'+f for f in stackfiles]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so4_7eTmIaAr",
        "outputId": "0c8d7dcd-6b00-4cb4-be6c-bc990512167d"
      },
      "source": [
        "#for now only keep the masks we cleaned have movies for - also in the correct order to match up\n",
        "maskpaths = [maskpaths[x] for x in [1, 0, 4]]\n",
        "maskpaths"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211106_1_1_manualROIs_tm4_syt.mat',\n",
              " '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210815_0_1_manualROIs_mix1_syt.mat',\n",
              " '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210728_0_1_manualROIs_tm2_tm9_syt.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O3Ta8XtKXFQ",
        "outputId": "151552e1-b7f6-4ef0-eacf-dd88b20b6e34"
      },
      "source": [
        "#join the lists into pairs of tuples\n",
        "mask_stack_pairs = list(map(lambda x, y:[x,y], maskpaths, stackpaths))\n",
        "mask_stack_pairs"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211106_1_1_manualROIs_tm4_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_syt_.h5'],\n",
              " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210815_0_1_manualROIs_mix1_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5'],\n",
              " ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210728_0_1_manualROIs_tm2_tm9_syt.mat',\n",
              "  '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzmBKC4DsV2y"
      },
      "source": [
        "## Initialize parameters object with starter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24iRFksugPTv"
      },
      "source": [
        "#create parameters object\n",
        "opts = params.CNMFParams()\n",
        "#fname will be assigned in the loop\n",
        "fnames = []\n",
        "subfolder = 'stackRaw_mc'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLzfCy0wFb-g"
      },
      "source": [
        "# set up some parameters for extraction\n",
        "#fnames = path to video file, set above\n",
        "                        # file(s) to be analyzed\n",
        "is_patches = True       # flag for processing in patches or not - CONFIRMED FROM CARL\n",
        "fr = 20                 # approximate frame rate of data - CONFIRMED FPS\n",
        "decay_time = .4        # length of transient - CONFIRMED APPROPRIATE FOR OUR INDICATOR GCaMP6f\n",
        "dims = [128, 256]\n",
        "\n",
        "if is_patches:          # PROCESS IN PATCHES AND THEN COMBINE - not used\n",
        "    rf = 25             # half size of each patch - not used\n",
        "    stride = 5          # overlap between patches - not used\n",
        "    K = 3               # number of components in each patch - not used\n",
        "else:                   # PROCESS THE WHOLE FOV AT ONCE\n",
        "    rf = None           # setting these parameters to None - CONFIRMED\n",
        "    stride = None       # will run CNMF on the whole FOV - CONFIRMED\n",
        "    K = 20              # number of neurons expected (in the whole FOV) - TUNE\n",
        "\n",
        "gSig = [4, 4]           # expected half size of neurons - TUNE\n",
        "merge_thresh = 0.9     # merging threshold, max correlation allowed - TUNE\n",
        "p = 1                   # order of the autoregressive system - From carl's code, probably should be 1\n",
        "gnb = 2                 # global background order - TUNE\n",
        "\n",
        "opts.set('data', {'fnames': fnames,\n",
        "                   'fr': fr,\n",
        "                   'decay_time': decay_time,\n",
        "                   'dims': dims,\n",
        "                   'rf': rf,\n",
        "                   'stride': stride,\n",
        "                   'K': K,\n",
        "                   'gSig': gSig,\n",
        "                   'merge_thr': merge_thresh,\n",
        "                   'p': p,\n",
        "                   'nb': gnb\n",
        "                  })\n",
        "\n",
        "\n",
        "# %% COMPONENT EVALUATION\n",
        "# the components are evaluated in three ways:\n",
        "#   a) the shape of each component must be correlated with the data\n",
        "#   b) a minimum peak SNR is required over the length of a transient\n",
        "#   c) each shape passes a CNN based classifier (this will pick up only neurons\n",
        "#           and filter out active processes)\n",
        "\n",
        "\n",
        "#Not sure if these should be tuned or not\n",
        "\n",
        "min_SNR = 2.5      # peak SNR for accepted components (if above this, acept)\n",
        "rval_thr = 0.9     # space correlation threshold (if above this, accept)\n",
        "use_cnn = False      # use the CNN classifier\n",
        "min_cnn_thr = 0.9  # if cnn classifier predicts below this value, reject\n",
        "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n",
        "\n",
        "opts.set('quality', {'min_SNR': min_SNR,\n",
        "                                'rval_thr': rval_thr,\n",
        "                                'use_cnn': use_cnn,\n",
        "                                'min_cnn_thr': min_cnn_thr,\n",
        "                                'cnn_lowest': cnn_lowest})\n",
        "\n",
        "#Manually assign subfolder variable\n",
        "opts.motion['var_name_hdf5'] = subfolder\n",
        "opts.data['var_name_hdf5'] = subfolder\n",
        "\n",
        "#for development purposes heavily downsample to save time\n",
        "opts.init['ssub'] = 5\n",
        "opts.init['tsub'] = 5"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T37S56psacn"
      },
      "source": [
        "## Define pipeline function to run Caiman"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yT59EZk84XL"
      },
      "source": [
        "#Function to run cnmf, run seeded cnmf using masks, then return validation\n",
        "\n",
        "def score_params(path_to_stack, path_to_masks, opts):\n",
        "  import warnings\n",
        "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "  fnames = [path_to_stack]\n",
        "\n",
        "  try:\n",
        "    \n",
        "    c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "        backend='local', n_processes=None, single_thread=False)\n",
        "    \n",
        "    #Run CNMF on raw stack using passed params\n",
        "    cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
        "    print('cnm object initialized')\n",
        "    cnm = cnm.fit_file(motion_correct = False, include_eval=True)\n",
        "    print('cnmf and component evaluation completed')\n",
        "\n",
        "\n",
        "    #Read in masks and reformat\n",
        "    g = h5py.File(path_to_masks, 'r')\n",
        "\n",
        "    #transpose the matrix and save to an array A\n",
        "    mask_A = g['bwMaskStack'][:].T\n",
        "\n",
        "    g.close()\n",
        "\n",
        "    #rearrange the dimensions and show the new shape\n",
        "    mask_A = mask_A.transpose(1,0,2)\n",
        "\n",
        "    #reshape to 2D, first dimension is 128*256 (32768), 2nd dimension is the # of ROI's\n",
        "    mask_A = mask_A.reshape((mask_A.shape[1]*mask_A.shape[0]), mask_A.shape[2])\n",
        "\n",
        "    #convert the values from 0/1 to boolean False/True\n",
        "    mask_A = np.array(mask_A, dtype=bool)\n",
        "    print('mask read in and reformatted')\n",
        "\n",
        "    dview.terminate()\n",
        "\n",
        "    c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "        backend='local', n_processes=None, single_thread=False)\n",
        "\n",
        "    #Seeded CNMF only works when seeded using mmap\n",
        "    import pathlib\n",
        "\n",
        "    #create memmory map location for the original movie\n",
        "    fname_new = cm.save_memmap(fnames, base_name=pathlib.Path(fnames[0]).stem + \"_memmap_\", order='C')\n",
        "\n",
        "    #read data from mmap location\n",
        "    Yr, dims, T = cm.load_memmap(fname_new)\n",
        "\n",
        "    # load frames in python format (T x X x Y)\n",
        "    mov = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
        "    print('movie matrix loaded for seeded cnmf')\n",
        "\n",
        "\n",
        "    #For seeded CNMF, need to adjust some params\n",
        "    rf = None\n",
        "    only_init = False\n",
        "\n",
        "    opts.patch['only_init'] = only_init\n",
        "    opts.patch['rf'] = rf\n",
        "\n",
        "    print('params adjusted for seeded cnmf')\n",
        "    \n",
        "    #Initialize a new cnmf object and pass in our masks as the \"Ain\" param\n",
        "    #\"Ain\" is A-in, meaning the A matrix holding the spatial footprints of the roi's\n",
        "    cnm_seeded = cnmf.CNMF(n_processes, params=opts, dview=dview, Ain=mask_A)\n",
        "    print('seeded cnmf object initialized')\n",
        "    cnm_seeded.fit(mov)\n",
        "    print('seeded cnmf completed')\n",
        "\n",
        "    #Try running register_ROIs and see what happens\n",
        "    matched_ROIs1, matched_ROIs2, non_matched1, non_matched2, performance, A2 = cm.base.rois.register_ROIs(cnm_seeded.estimates.A, cnm.estimates.A, dims=dims)\n",
        "    print('validation and scoring completed')\n",
        "\n",
        "    #terminate cluster\n",
        "    dview.terminate()\n",
        "\n",
        "    #return performance metrics\n",
        "    return {'matched_ROIs1': matched_ROIs1,\n",
        "            'matched_ROIs2': matched_ROIs2,\n",
        "            'non_matched1': non_matched1,\n",
        "            'non_matched2': non_matched2, \n",
        "            'performance': performance,\n",
        "            'A2': A2}\n",
        "\n",
        "  except:\n",
        "    print('failed')\n",
        "    dview.terminate()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AT-5zoysj-B"
      },
      "source": [
        "## Eventually, adjust params within loops to implement gridsearch\n",
        "\n",
        "### For now, just loop through the 3 pairs at the moment and print accuracy results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJtcnIiCBWQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "1b456dd0-696d-40e7-ce2d-9fbdd78882db"
      },
      "source": [
        "#loop through the stack-mask pairs and print the accuracy results\n",
        "\n",
        "\n",
        "#this will all be wrapped in another function that sets parameters\n",
        "#this loop will run all stacks through caiman using a given set of parameters to get the accuracy\n",
        "for pair in mask_stack_pairs:\n",
        "  path_to_stack = pair[1]\n",
        "  path_to_masks = pair[0]\n",
        "\n",
        "  print(path_to_stack)\n",
        "  print(path_to_masks)\n",
        "\n",
        "\n",
        "  opts.data['fnames'] = [path_to_stack]\n",
        "  print(opts.data['fnames'])\n",
        "\n",
        "  results = score_params(path_to_stack=path_to_stack, \\\n",
        "             path_to_masks=path_to_masks, \\\n",
        "             opts=opts)\n",
        "  \n",
        "  #need to add storage to save results\n",
        "  #could adjust this to only output the average performance at the end of a loop\n",
        "  print(results['performance'])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_syt_.h5\n",
            "../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210815_0_1_manualROIs_mix1_syt.mat\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_211106_1_1_stackRaw_mc_tm4_syt_.h5']\n",
            "cnm object initialized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnmf and component evaluation completed\n",
            "mask read in and reformatted\n",
            "movie matrix loaded for seeded cnmf\n",
            "params adjusted for seeded cnmf\n",
            "seeded cnmf object initialized\n",
            "spatial support for each components given by the user\n",
            "seeded cnmf completed\n",
            "validation and scoring completed\n",
            "{'recall': 0.0, 'precision': 0.0, 'accuracy': 0.0, 'f1_score': 0.0}\n",
            "../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5\n",
            "../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/211106_1_1_manualROIs_tm4_syt.mat\n",
            "['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210815_0_1_stackRaw_mc_mix1_syt_.h5']\n",
            "cnm object initialized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  ConvergenceWarning,\n",
            "Process ForkPoolWorker-3:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/content/CaImAn/caiman/source_extraction/cnmf/spatial.py\", line 413, in regression_ipyparallel\n",
            "    a_lrs = clf.fit(np.array(c.T), np.ravel(y))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5535e938a529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_stack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_stack\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0mpath_to_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_masks\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'performance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt9VjwbVsvI7"
      },
      "source": [
        "## Old working code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IpXfCGmIo5Y",
        "outputId": "4217ace1-ea9e-4301-e349-1deeefec0534"
      },
      "source": [
        "# # cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
        "# cnm = cnm.fit_file(motion_correct = False, include_eval=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMfPlzw8X0PQ",
        "outputId": "8ef04e78-0d1d-4931-aea4-811d2c1a350c"
      },
      "source": [
        "# #Read in masks and reformat\n",
        "# path_to_masks = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210728_0_1_manualROIs_tm2_tm9_syt.mat'\n",
        "# g = h5py.File(path_to_masks, 'r')\n",
        "\n",
        "# #transpose the matrix and save to an array A\n",
        "# mask_A = g['bwMaskStack'][:].T\n",
        "\n",
        "# g.close()\n",
        "\n",
        "# #rearrange the dimensions and show the new shape\n",
        "# mask_A = mask_A.transpose(1,0,2)\n",
        "\n",
        "# #reshape to 2D, first dimension is 128*256 (32768), 2nd dimension is the # of ROI's\n",
        "# mask_A = mask_A.reshape((mask_A.shape[1]*mask_A.shape[0]), mask_A.shape[2])\n",
        "\n",
        "# #convert the values from 0/1 to boolean False/True\n",
        "# mask_A = np.array(mask_A, dtype=bool)\n",
        "# print('mask read in and reformatted')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask read in and reformatted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ6G0vf2Xna1",
        "outputId": "92c57118-60f6-493c-de2b-0acc606277c9"
      },
      "source": [
        "# import warnings\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# #Seeded CNMF only works when seeded using mmap\n",
        "# import pathlib\n",
        "\n",
        "# #create memmory map location for the original movie\n",
        "# fname_new = cm.save_memmap(fnames, base_name=pathlib.Path(fnames[0]).stem + \"_memmap_\", order='C')\n",
        "#  #read data from mmap location\n",
        "# Yr, dims, T = cm.load_memmap(fname_new)\n",
        "\n",
        "# # load frames in python format (T x X x Y)\n",
        "# mov = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
        "# print('movie matrix loaded for seeded cnmf')\n",
        "\n",
        "# dview.terminate()\n",
        "\n",
        "# c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "#     backend='local', n_processes=None, single_thread=False)\n",
        "\n",
        "# #For seeded CNMF, need to adjust some params\n",
        "# rf = None\n",
        "# only_init = False\n",
        "\n",
        "# opts.patch['only_init'] = only_init\n",
        "# opts.patch['rf'] = rf\n",
        "\n",
        "# print('params adjusted for seeded cnmf')\n",
        "  \n",
        "# #Initialize a new cnmf object and pass in our masks as the \"Ain\" param\n",
        "# #\"Ain\" is A-in, meaning the A matrix holding the spatial footprints of the roi's\n",
        "# cnm_seeded = cnmf.CNMF(n_processes, params=opts, dview=dview, Ain=mask_A)\n",
        "# print('seeded cnmf object initialized')\n",
        "# cnm_seeded.fit(mov)\n",
        "# print('seeded cnmf completed')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movie matrix loaded for seeded cnmf\n",
            "params adjusted for seeded cnmf\n",
            "seeded cnmf object initialized\n",
            "spatial support for each components given by the user\n",
            "seeded cnmf completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/dia.py:300: RuntimeWarning: divide by zero encountered in remainder\n",
            "  c = np.arange(num_rows, dtype=np.intc) - (offsets % max_dim)[:, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3N_kLqjZN22",
        "outputId": "5431e757-5fe0-49e3-cfca-ffdbd00bf80b"
      },
      "source": [
        "# matched_ROIs1, matched_ROIs2, non_matched1, non_matched2, performance, A2 = cm.base.rois.register_ROIs(cnm_seeded.estimates.A, cnm.estimates.A, dims=dims)\n",
        "# performance"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.05128205128205128,\n",
              " 'f1_score': 0.0975609756097561,\n",
              " 'precision': 0.06896551724137931,\n",
              " 'recall': 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq9jP22tkerZ"
      },
      "source": [
        "# dview.terminate()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbF05-Gf880B",
        "outputId": "670b9bcb-5677-4b9e-ac3d-f8c664202df1"
      },
      "source": [
        "# results = score_params(path_to_stack=fnames[0], \\\n",
        "#              path_to_masks='../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210728_0_1_manualROIs_tm2_tm9_syt.mat', \\\n",
        "#              opts=opts)\n",
        "# results['performance']"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnm object initialized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  ConvergenceWarning,\n",
            "WARNING:root:Component 9 is only active jointly with neighboring components. Space correlation calculation might be unreliable.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnmf and component evaluation completed\n",
            "mask read in and reformatted\n",
            "movie matrix loaded for seeded cnmf\n",
            "params adjusted for seeded cnmf\n",
            "seeded cnmf object initialized\n",
            "spatial support for each components given by the user\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/dia.py:300: RuntimeWarning: divide by zero encountered in remainder\n",
            "  c = np.arange(num_rows, dtype=np.intc) - (offsets % max_dim)[:, None]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seeded cnmf completed\n",
            "validation and scoring completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.05128205128205128,\n",
              " 'f1_score': 0.0975609756097561,\n",
              " 'precision': 0.06896551724137931,\n",
              " 'recall': 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqDS85Nh91TG"
      },
      "source": [
        "# dview.terminate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3ESP19w93KD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}