{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visual Param Tinkering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Cp8ZM0yRT8SBoer828iJG0-EktWnefDn",
      "authorship_tag": "ABX9TyP31THjK8DYYPmIO/cCrcR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenneal/capstone-visual-neuroscience/blob/Dylan/Visual_Param_Tinkering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook extracts the basic components from the Validation Wrapper notebook for more convenient tinkering and visualizations of parameters"
      ],
      "metadata": {
        "id": "V7Wwz8OcGvDU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMQyPTVxwhVU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbIj2QeEAbTE",
        "outputId": "099d3bf0-e94f-439e-9595-502c504f8759"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrE1xeswQNHM",
        "outputId": "2036f3df-51d0-4eeb-868e-88c68c4f9b56"
      },
      "source": [
        "# Install CaImAn - takes around 2 minutes\n",
        "\n",
        "!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "%cd '/content/CaImAn/'\n",
        "!pip install -e .\n",
        "\n",
        "# Install caiman dependencies (&> /dev/null will suppress the hundreds of printed lines in the output)\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "\n",
        "#import other dependencies\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "#IMPORTANT! Newer versions of h5py will cause errors when saving results\n",
        "!pip install h5py==2.10.0\n",
        "import h5py\n",
        "\n",
        "#Set up caiman\n",
        "!python setup.py build_ext -i\n",
        "\n",
        "#Other file setup\n",
        "!python caimanmanager.py install --inplace\n",
        "\n",
        "#Caiman imports\n",
        "import caiman as cm\n",
        "from caiman.motion_correction import MotionCorrect\n",
        "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "from caiman.utils.utils import download_demo\n",
        "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
        "from caiman.summary_images import local_correlations_movie_offline\n",
        "from scipy.ndimage import center_of_mass\n",
        "from IPython.display import display, clear_output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CaImAn'...\n",
            "remote: Enumerating objects: 24960, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 24960 (delta 0), reused 2 (delta 0), pack-reused 24954\u001b[K\n",
            "Receiving objects: 100% (24960/24960), 518.36 MiB | 29.47 MiB/s, done.\n",
            "Resolving deltas: 100% (16746/16746), done.\n",
            "Checking out files: 100% (317/317), done.\n",
            "/content/CaImAn\n",
            "Obtaining file:///content/CaImAn\n",
            "Installing collected packages: caiman\n",
            "  Running setup.py develop for caiman\n",
            "Successfully installed caiman-1.9.7\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "running build_ext\n",
            "Installed /root/caiman_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzmBKC4DsV2y"
      },
      "source": [
        "## Initialize parameters object with starter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24iRFksugPTv"
      },
      "source": [
        "#create parameters object\n",
        "opts = params.CNMFParams()\n",
        "#fname will be assigned in the loop\n",
        "fnames = []\n",
        "subfolder = 'stackRaw_mc'\n",
        "opts.motion['var_name_hdf5'] = subfolder\n",
        "opts.data['var_name_hdf5'] = subfolder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLzfCy0wFb-g"
      },
      "source": [
        "# set initial values for extraction and evaluation\n",
        "# most of these are specific to our data and will not need to be changed during optimization\n",
        "\n",
        "# overall params about our data\n",
        "\n",
        "fr = 20                 # approximate frame rate of data - CONFIRMED FPS\n",
        "decay_time = .4         # length of transient - CONFIRMED APPROPRIATE FOR OUR INDICATOR GCaMP6f\n",
        "dims = [128, 256]       # dimensions of the FOV in pixels - CONFIRMED\n",
        "dxy = [.29, .29]        # resolution of 1 pixel in um - CONFIRMED BY CARL\n",
        "\n",
        "opts.set('data', {'fnames': fnames,\n",
        "                   'fr': fr,\n",
        "                   'decay_time': decay_time,\n",
        "                   'dims': dims,\n",
        "                   'dxy': dxy\n",
        "                  })\n",
        "\n",
        "\n",
        "# params related to the temporal traces\n",
        "\n",
        "p = 0                   # order of the autoregressive system - 0 from carl's code\n",
        "fudge_factor = 1        # (default is 0.96; Carl's value = 1) -- bias correction factor for discrete time constants\n",
        "ITER = 5                # (default is 2; Carl's value=5) -- block coordinate descent iterations\n",
        "tnb = 1                  # temporal global background components - TUNE\n",
        "\n",
        "opts.set('temporal', {'p': p,\n",
        "                      'fudge_factor': fudge_factor,\n",
        "                      'ITER': ITER,\n",
        "                      'nb': tnb\n",
        "                 })\n",
        "\n",
        "# p is also set in the preprocessing step\n",
        "opts.set('preprocess', {'p': p\n",
        "                 })\n",
        "\n",
        "\n",
        "\n",
        "# params related to the FOV and patches for parallel processing\n",
        "\n",
        "is_patches = True      # flag for processing in patches or not - turn on or off\n",
        "\n",
        "if is_patches:          # PROCESS IN PATCHES AND THEN COMBINE \n",
        "    rf = 25             # half size of each patch -not tuned\n",
        "    stride = 5          # overlap between patches -not tuned\n",
        "    K = 3               # number of components in each patch - TUNE - gets set later in INIT params\n",
        "    p_patch = p\n",
        "\n",
        "else:                   # PROCESS THE WHOLE FOV AT ONCE\n",
        "    rf = None           # setting these parameters to None Not used\n",
        "    stride = None       # will run CNMF on the whole FOV not used\n",
        "    K = 10              # number of neurons expected (in the whole FOV) - not used\n",
        "\n",
        "n_processes = 2         # Number of processes to run in parallel, 2 for 2 cores available in Colab\n",
        "\n",
        "opts.set('patch', {'rf': rf,\n",
        "                   'stride': stride,\n",
        "                   'n_processes': n_processes\n",
        "                  })   \n",
        "\n",
        "\n",
        "\n",
        "# initialization params\n",
        "ssub = 2                # spatial downsampling\n",
        "tsub = 2                # temporal downsampling\n",
        "ssub_B = 3              # background spatial downsampling\n",
        "gSig = [0,0]            # radius (half-size) of average neurons (in pixels)\n",
        "nb = 1                  # number of background components\n",
        "#method_init = 'greedy_roi' #Caiman defaults to greedy_roi, carl's code uses sparse_nmf, but this runs MUCH slower\n",
        "\n",
        "opts.set('init', {'K': K,            # declared above in patch params    \n",
        "                   'gSig': gSig,      \n",
        "                   'tsub': tsub,\n",
        "                   'ssub': ssub,\n",
        "                   'ssub_B': ssub_B,\n",
        "                   'nb': nb#,\n",
        "                   #'method_init': method_init\n",
        "                  })\n",
        "\n",
        "# parameters related to merging correlated ROIs\n",
        "merge_thr = 0.96     # merging threshold, max correlation allowed - FOUND VIA TUNING\n",
        "\n",
        "opts.set('merging', {'merge_thr': merge_thr\n",
        "                            })\n",
        "\n",
        "\n",
        "#set some spatial params\n",
        "snb = 2                  # spatial global background components - TUNE\n",
        "\n",
        "opts.set('spatial', {'nb': snb\n",
        "                            })\n",
        "\n",
        "# %% COMPONENT EVALUATION\n",
        "# the components are evaluated in three ways:\n",
        "#   a) the shape of each component must be correlated with the data\n",
        "#   b) a minimum peak SNR is required over the length of a transient\n",
        "#   c) each shape passes a CNN based classifier (this will pick up only neurons\n",
        "#           and filter out active processes)\n",
        "\n",
        "\n",
        "#Not sure if these should be tuned or not\n",
        "\n",
        "min_SNR = 2.5      # peak SNR for accepted components (if above this, acept)\n",
        "SNR_lowest = 1         # minimum SNR for accepted components (if below this, reject)\n",
        "rval_thr = 0.9     # space correlation threshold (if above this, accept)\n",
        "\n",
        "use_cnn = True      # use the CNN classifier affects if 2 below params are used\n",
        "min_cnn_thr = 0.9  # if cnn classifier predicts below this value, reject\n",
        "cnn_lowest = 0.1   # neurons with cnn probability lower than this value are rejected\n",
        "\n",
        "opts.set('quality', {'min_SNR': min_SNR,\n",
        "                     'SNR_lowest': SNR_lowest,\n",
        "                     'rval_thr': rval_thr,\n",
        "                     'use_cnn': use_cnn,\n",
        "                     'min_cnn_thr': min_cnn_thr,\n",
        "                     'cnn_lowest': cnn_lowest})\n",
        "\n",
        "\n",
        "#Manually assign subfolder variable\n",
        "opts.motion['var_name_hdf5'] = subfolder\n",
        "opts.data['var_name_hdf5'] = subfolder\n",
        "\n",
        "\n",
        "\n",
        "#motion correction not used for our parameter tuning. Leaving these params here in case they get used in the future.\n",
        "\n",
        "#%% First setup some parameters for data and motion correction\n",
        "# dataset dependent parameters\n",
        "\n",
        "# ADJUSTED FROM DEFAULTS TO CARL'S PARAMS ON 11/13 (not completely)\n",
        "\n",
        "fr = 20             # imaging rate in frames per second\n",
        "decay_time = 0.4    # length of a typical transient in seconds\n",
        "dxy = (.29, .29)      # spatial resolution in x and y in (um per pixel)\n",
        "# note the lower than usual spatial resolution here\n",
        "max_shift_um = (12., 12.)       # maximum shift in um\n",
        "patch_motion_um = (100., 100.)  # patch size for non-rigid correction in um\n",
        "\n",
        "# motion correction parameters\n",
        "pw_rigid = False       # flag to select rigid vs pw_rigid motion correction\n",
        "# maximum allowed rigid shift in pixels\n",
        "max_shifts = [int(a/b) for a, b in zip(max_shift_um, dxy)]\n",
        "# start a new patch for pw-rigid motion correction every x pixels\n",
        "strides = tuple([int(a/b) for a, b in zip(patch_motion_um, dxy)])\n",
        "# overlap between pathes (size of patch in pixels: strides+overlaps)\n",
        "overlaps = (24, 24)\n",
        "# maximum deviation allowed for patch with respect to rigid shifts\n",
        "max_deviation_rigid = 3\n",
        "\n",
        "opts.set('motion', {\n",
        "    'fnames': fnames,\n",
        "    'fr': fr,\n",
        "    'decay_time': decay_time,\n",
        "    'dxy': dxy,\n",
        "    'pw_rigid': pw_rigid,\n",
        "    'max_shifts': max_shifts,\n",
        "    'strides': strides,\n",
        "    'overlaps': overlaps,\n",
        "    'max_deviation_rigid': max_deviation_rigid,\n",
        "    'border_nan': 'copy'\n",
        "})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T37S56psacn"
      },
      "source": [
        "## Run on a single movie and visualize how the params performed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#arbitrary movie to extract\n",
        "opts.set('data', {'fnames': ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED/CLEAN_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5']})\n",
        "  \n",
        "if 'dview' in locals():\n",
        "  cm.stop_server(dview=dview)\n",
        "dview = cm.cluster.start_server(ncpus=2)\n",
        "\n",
        "#Run CNMF\n",
        "print('starting cnmf')\n",
        "cnm = cnmf.CNMF(n_processes = 2, params=opts, dview=dview)\n",
        "cnm = cnm.fit_file(motion_correct = False, include_eval=True)\n",
        "print('cnmf and component evaluation completed')\n",
        "cm.stop_server(dview=dview)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "mEKpt8VJKwFz",
        "outputId": "afd699bd-5953-44b4-ad3f-64f09891b43b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "...............starting cnmf\n",
            "USING MODEL:/root/caiman_data/model/cnn_model.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/CaImAn/caiman/components_evaluation.py:330: RuntimeWarning: invalid value encountered in true_divide\n",
            "  final_crops = np.array([cv2.resize(im / np.linalg.norm(im), (patch_size, patch_size)) for im in crop_imgs])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 31ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-410f7606569e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starting cnmf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcnm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcnm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotion_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnmf and component evaluation completed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CaImAn/caiman/source_extraction/cnmf/cnmf.py\u001b[0m in \u001b[0;36mfit_file\u001b[0;34m(self, motion_correct, indices, include_eval)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mcnm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetrend_df_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantileMin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mcnm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mcnm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CaImAn/caiman/source_extraction/cnmf/cnmf.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'.hdf5'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaiman\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_relocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0msave_dict_to_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File extension not supported for cnmf.save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CaImAn/caiman/utils/utils.py\u001b[0m in \u001b[0;36msave_dict_to_hdf5\u001b[0;34m(dic, filename, subdir)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mrecursively_save_dict_contents_to_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dict_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CaImAn/caiman/utils/utils.py\u001b[0m in \u001b[0;36mrecursively_save_dict_contents_to_group\u001b[0;34m(h5file, path, dic)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mh5file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'CNMFParams'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Estimates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#  parameter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0mrecursively_save_dict_contents_to_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot save {type(item)} type for key '{key}'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CaImAn/caiman/utils/utils.py\u001b[0m in \u001b[0;36mrecursively_save_dict_contents_to_group\u001b[0;34m(h5file, path, dic)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0mh5file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error while saving {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0;31m# save dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error while saving cnn_preds."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#playing with the built-in visualization methods\n",
        "#I think we need to loop this over the different rois to see them\n",
        "cnm.estimates.view_components(img=cnm.estimates.Cn)"
      ],
      "metadata": {
        "id": "V5CIxPYzOO3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOT WORKING YET\n",
        "#ripped from the other notebook but nor adjusted to these varnames\n",
        "\n",
        "#visualize our results\n",
        "import scipy.sparse as sparse\n",
        "dims = [128,256]\n",
        "for x in keys:  \n",
        "\n",
        "  f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 3), constrained_layout=True) \n",
        "\n",
        "  ax1.set_title('Original Correlation Image')\n",
        "  ax1.imshow(np.reshape(results[x]['Correlation_img'], dims, order=\"F\"), aspect='auto')\n",
        "\n",
        "  #plot rois\n",
        "  roiimg = np.zeros((32768,1))\n",
        "  for i in range(results[x]['cnm_estimates'].A.shape[1]):\n",
        "    roiimg = roiimg+results[x]['cnm_estimates'].A[:,i]\n",
        "  ax2.set_title('ROIs Extracted')\n",
        "  ax2.imshow(np.reshape(roiimg, dims, order=\"F\"), aspect='auto')\n",
        "\n",
        "  #extracted masks - might not be imporant at all\n",
        "  M = results[x]['cnm_estimates'].A > 0\n",
        "  img = np.zeros((32768,1))\n",
        "  for i in range(M.shape[1]):\n",
        "    img = img+M[:,i]\n",
        "\n",
        "  ax3.set_title(f'Masks Extracted')\n",
        "  ax3.imshow(np.reshape(img, dims, order=\"F\"), aspect='auto')\n",
        "\n",
        "  A_sparse = sparse.csc_matrix(results[x]['ROI_mask'])\n",
        "  maskimg = np.zeros((32768,1))\n",
        "\n",
        "  f.suptitle(f'Results for {x}: {results[x][\"performance\"]}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jZ-2RFl3LkjE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}