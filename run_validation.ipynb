{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_validation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenneal/capstone-visual-neuroscience/blob/Dylan/run_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_33IV1Cm9BNl"
      },
      "source": [
        "This notebook is to set up a process for running cnmf and validation in a single call from score_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMQyPTVxwhVU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbIj2QeEAbTE",
        "outputId": "fe9e61ba-824e-4ac9-81a6-25990a8608b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrE1xeswQNHM",
        "outputId": "9e49ff61-4384-4147-9282-f3aef4d118db"
      },
      "source": [
        "# Install CaImAn - takes around 2 minutes\n",
        "\n",
        "!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "%cd '/content/CaImAn/'\n",
        "!pip install -e .\n",
        "\n",
        "# Install caiman dependencies (&> /dev/null will suppress the hundreds of printed lines in the output)\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "\n",
        "#import other dependencies\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "#IMPORTANT! Newer versions of h5py will cause errors when saving results\n",
        "!pip install h5py==2.10.0\n",
        "import h5py\n",
        "\n",
        "#Set up caiman\n",
        "!python setup.py build_ext -i\n",
        "\n",
        "#Other file setup\n",
        "!python caimanmanager.py install --inplace\n",
        "\n",
        "#Caiman imports\n",
        "import caiman as cm\n",
        "from caiman.motion_correction import MotionCorrect\n",
        "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "from caiman.utils.utils import download_demo\n",
        "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
        "from caiman.summary_images import local_correlations_movie_offline\n",
        "from scipy.ndimage import center_of_mass\n",
        "from IPython.display import display, clear_output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CaImAn'...\n",
            "remote: Enumerating objects: 24916, done.\u001b[K\n",
            "remote: Counting objects: 100% (851/851), done.\u001b[K\n",
            "remote: Compressing objects: 100% (421/421), done.\u001b[K\n",
            "remote: Total 24916 (delta 475), reused 739 (delta 414), pack-reused 24065\u001b[K\n",
            "Receiving objects: 100% (24916/24916), 518.52 MiB | 27.67 MiB/s, done.\n",
            "Resolving deltas: 100% (16688/16688), done.\n",
            "Checking out files: 100% (317/317), done.\n",
            "/content/CaImAn\n",
            "Obtaining file:///content/CaImAn\n",
            "Installing collected packages: caiman\n",
            "  Running setup.py develop for caiman\n",
            "Successfully installed caiman-1.9.6\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 28.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "running build_ext\n",
            "Installed /root/caiman_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEoEQAZAAVzh"
      },
      "source": [
        "## Define score_params function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guSSvTxwAU4D"
      },
      "source": [
        "def score_params(path_to_stack, path_to_masks, opts):\n",
        "  fnames = [path_to_stack]\n",
        "\n",
        "  #start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
        "  if 'dview' in locals():\n",
        "      cm.stop_server(dview=dview)\n",
        "  c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "      backend='local', n_processes=None, single_thread=False)\n",
        "  \n",
        "  print('cluster started')\n",
        "\n",
        "  #Run CNMF on raw stack using passed params\n",
        "  cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
        "  print('cnm object initialized')\n",
        "  cnm = cnm.fit_file(motion_correct = False, include_eval=True)\n",
        "  print('cnmf and component evaluation completed')\n",
        "\n",
        "\n",
        "  #Read in masks and reformat\n",
        "  g = h5py.File(path_to_masks, 'r')\n",
        "\n",
        "  #transpose the matrix and save to an array A\n",
        "  mask_A = g['bwMaskStack'][:].T\n",
        "\n",
        "  g.close()\n",
        "\n",
        "  #rearrange the dimensions and show the new shape\n",
        "  mask_A = mask_A.transpose(1,0,2)\n",
        "\n",
        "  #reshape to 2D, first dimension is 128*256 (32768), 2nd dimension is the # of ROI's\n",
        "  mask_A = mask_A.reshape((mask_A.shape[1]*mask_A.shape[0]), mask_A.shape[2])\n",
        "\n",
        "  #convert the values from 0/1 to boolean False/True\n",
        "  mask_A = np.array(mask_A, dtype=bool)\n",
        "  print('mask read in and reformatted')\n",
        "\n",
        "\n",
        "\n",
        "  #Seeded CNMF only works when seeded using mmap\n",
        "  import pathlib\n",
        "\n",
        "  #create memmory map location for the original movie\n",
        "  fname_new = cm.save_memmap(fnames, base_name=pathlib.Path(fnames[0]).stem + \"_memmap_\", order='C')\n",
        "\n",
        "  #read data from mmap location\n",
        "  Yr, dims, T = cm.load_memmap(fname_new)\n",
        "\n",
        "  # load frames in python format (T x X x Y)\n",
        "  mov = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
        "  print('movie matrix loaded for seeded cnmf')\n",
        "\n",
        "\n",
        "  #For seeded CNMF, need to adjust some params\n",
        "  rf = None\n",
        "  only_init = False\n",
        "\n",
        "  opts.patch['only_init'] = only_init\n",
        "  opts.patch['rf'] = rf\n",
        "\n",
        "  print('params adjusted for seeded cnmf')\n",
        "\n",
        "  #restart cluster to clean up memory\n",
        "  cm.stop_server(dview=dview)\n",
        "  c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "      backend='local', n_processes=None, single_thread=False)\n",
        "  \n",
        "  print('cluster restarted to clean up memory')\n",
        "  \n",
        "  #Initialize a new cnmf object and pass in our masks as the \"Ain\" param\n",
        "  #\"Ain\" is A-in, meaning the A matrix holding the spatial footprints of the roi's\n",
        "  cnm_seeded = cnmf.CNMF(n_processes, params=opts, dview=dview, Ain=mask_A)\n",
        "  print('seeded cnmf object initialized')\n",
        "  cnm_seeded.fit(mov)\n",
        "  print('seeded cnmf completed')\n",
        "\n",
        "  #Try running register_ROIs and see what happens\n",
        "  matched_ROIs1, matched_ROIs2, non_matched1, non_matched2, performance, A2 = cm.base.rois.register_ROIs(cnm_seeded.estimates.A, cnm.estimates.A, dims=dims)\n",
        "  print('validation and scoring completed')\n",
        "\n",
        "  #terminate cluster\n",
        "  cm.stop_server(dview=dview)\n",
        "\n",
        "  #return performance metrics\n",
        "  return matched_ROIs1, matched_ROIs2, non_matched1, non_matched2, performance, A2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaDDGoWo9eVd"
      },
      "source": [
        "## Set up parameters object\n",
        "\n",
        "### this object will be different each time we pass it through. This is the object we tweak for our gridsearch\n",
        "### most of this can be removed eventually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mHcMb_h9toG"
      },
      "source": [
        "#temporary, declare fname, subfolder, and mask path ahead of time.\n",
        "#will need to implement this in a loop for gridsearch\n",
        "\n",
        "#temporarily running off of subset of movie, just 500 frames\n",
        "fnames = ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/subset_stackRaw_mc.h5'] #needs to be a list\n",
        "subfolder = 'stackRaw_mc' #name of folder within mat file\n",
        "path_to_masks = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/manualROIs_fixed/210728_0_1_manualROIs_tm2_tm9_syt.mat' #not a list\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR9XSHin9TW1"
      },
      "source": [
        "#create parameters object\n",
        "opts = params.CNMFParams()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLzfCy0wFb-g"
      },
      "source": [
        "# set up some parameters for extraction\n",
        "#fnames = path to video file, set above\n",
        "                        # file(s) to be analyzed\n",
        "is_patches = False       # flag for processing in patches or not - CONFIRMED FROM CARL\n",
        "fr = 20                 # approximate frame rate of data - CONFIRMED FPS\n",
        "decay_time = .4        # length of transient - CONFIRMED APPROPRIATE FOR OUR INDICATOR GCaMP6f\n",
        "dims = [128, 256]\n",
        "\n",
        "if is_patches:          # PROCESS IN PATCHES AND THEN COMBINE - not used\n",
        "    rf = 25             # half size of each patch - not used\n",
        "    stride = 5          # overlap between patches - not used\n",
        "    K = 3               # number of components in each patch - not used\n",
        "else:                   # PROCESS THE WHOLE FOV AT ONCE\n",
        "    rf = None           # setting these parameters to None - CONFIRMED\n",
        "    stride = None       # will run CNMF on the whole FOV - CONFIRMED\n",
        "    K = 40              # number of neurons expected (in the whole FOV) - TUNE\n",
        "\n",
        "gSig = [4, 4]           # expected half size of neurons - TUNE\n",
        "tau = 0                 ## Lauren adding std of gaussian kernel (size of neuron)\n",
        "                        ## gSig = size of kernel (default 2*tau + 1).\n",
        "merge_thresh = 0.95     # merging threshold, max correlation allowed - TUNE\n",
        "p = 0                   # order of the autoregressive system - From carl's code, probably should be 1\n",
        "gnb = 1                 # global background order - TUNE\n",
        "\n",
        "fudge = 1               ## Lauren adding temporal param fudge_factor (default is 0.96; Carl's value = 1) -- bias correction factor for discrete time constants\n",
        "temp_iter = 5           ## Lauren adding temporal param ITER (default is 2; Carl's value=5) -- block coordinate descent iterations\n",
        "srch_meth = 'dilate' ## Lauren adding spatial param search_method (Carl's set to 'dilate')\n",
        "thr_meth = 'nrg'        ## Lauren adding spatial param thr_method\n",
        "\n",
        "var_name_hdf5 = subfolder #variable to path caiman into the subfolder within our mat files\n",
        "\n",
        "opts.set('data', {'fnames': fnames,\n",
        "                   'fr': fr,\n",
        "                   'decay_time': decay_time,\n",
        "                   'dims': dims,\n",
        "                   'rf': rf,\n",
        "                   'stride': stride,\n",
        "                   'K': K,\n",
        "                   ## 'gSig': gSig,\n",
        "                   'merge_thr': merge_thresh,\n",
        "                   'p': p,\n",
        "                   'nb': gnb,\n",
        "                   'fudge_factor': fudge,\n",
        "                   'ITER': temp_iter,\n",
        "                   'thr_method': thr_meth,\n",
        "                   'method': srch_meth\n",
        "                  \n",
        "                  })\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JAZz7VSWsEd"
      },
      "source": [
        "# %% COMPONENT EVALUATION\n",
        "# the components are evaluated in three ways:\n",
        "#   a) the shape of each component must be correlated with the data\n",
        "#   b) a minimum peak SNR is required over the length of a transient\n",
        "#   c) each shape passes a CNN based classifier (this will pick up only neurons\n",
        "#           and filter out active processes)\n",
        "\n",
        "\n",
        "#Not sure if these should be tuned or not\n",
        "\n",
        "min_SNR = 2.5      # peak SNR for accepted components (if above this, acept)\n",
        "rval_thr = 0.9     # space correlation threshold (if above this, accept)\n",
        "use_cnn = True      # use the CNN classifier\n",
        "min_cnn_thr = 0.9  # if cnn classifier predicts below this value, reject\n",
        "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n",
        "\n",
        "opts.set('quality', {'min_SNR': min_SNR,\n",
        "                                'rval_thr': rval_thr,\n",
        "                                'use_cnn': use_cnn,\n",
        "                                'min_cnn_thr': min_cnn_thr,\n",
        "                                'cnn_lowest': cnn_lowest})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdscDTVLZKBe"
      },
      "source": [
        "#THE MOTION PARAMS DOES NOT PULL IN THE VAR NAME BY DEFAULT\n",
        "#NEEDS TO BE MANUALLY INJECTED SO IT GETS PULLED INTO MOTION CORRECT WITH THE REST\n",
        "\n",
        "opts.motion['var_name_hdf5'] = subfolder\n",
        "opts.data['var_name_hdf5'] = subfolder"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgdANpV7-37K"
      },
      "source": [
        "## Run score_params and return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYtKOv05-uki"
      },
      "source": [
        "%%capture\n",
        "matched_ROIs1, matched_ROIs2, non_matched1, non_matched2, performance, A2 = score_params(path_to_stack=fnames[0], \\\n",
        "                                                                                         path_to_masks=path_to_masks, \\\n",
        "                                                                                         opts=opts)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqRHp1gIBDjh",
        "outputId": "5d0a7a02-def1-4e46-c8f5-6a0cb21e2dbc"
      },
      "source": [
        "performance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.08333333333333333,\n",
              " 'f1_score': 0.15384615384615385,\n",
              " 'precision': 0.1111111111111111,\n",
              " 'recall': 0.25}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWoI1wgXDgen"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}