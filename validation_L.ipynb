{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "validation-L.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenneal/capstone-visual-neuroscience/blob/Lauren/validation_L.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ADamXOI9uB"
      },
      "source": [
        "The demo_pipeline file we've been working with uses some of the more advanced features of caiman which I think are throwing me off. \n",
        "\n",
        "This notebook is intended to implement a more stripped down version of the caiman pipeline with the goal of understanding the functions better and potentially being a platform to write our wrapper around for the parameter gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbIj2QeEAbTE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrE1xeswQNHM"
      },
      "source": [
        "# Install CaImAn - takes around 2 minutes\n",
        "!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "%cd '/content/CaImAn/'\n",
        "!pip install .\n",
        "\n",
        "# Install caiman dependencies (&> /dev/null will suppress the hundreds of printed lines in the output)\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "\n",
        "#import other dependencies\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#IMPORTANT! Newer versions of h5py will cause errors when saving results\n",
        "!pip install h5py==2.10.0\n",
        "import h5py\n",
        "\n",
        "#Set up caiman\n",
        "!python setup.py build_ext -i\n",
        "\n",
        "#Other file setup\n",
        "!python caimanmanager.py install --inplace\n",
        "\n",
        "#Caiman imports\n",
        "import caiman as cm\n",
        "from caiman.paths import caiman_datadir\n",
        "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "from caiman.summary_images import local_correlations_movie_offline\n",
        "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
        "from caiman.components_evaluation import estimate_components_quality_auto\n",
        "from caiman.base.rois import register_multisession\n",
        "from caiman.utils import visualization\n",
        "from caiman.utils.utils import download_demo\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJtcnIiCBWQb"
      },
      "source": [
        "#Using h5py to open and explore a test raw stack\n",
        "#paths into google drive to a random pre-motion correction movie\n",
        "stackRaw = h5py.File('../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/210815_0/210815_0_1_stackRaw_pmc_mix1_syt_.mat', 'r+')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFylueZ4Nb8l"
      },
      "source": [
        "#save movie array as a variable to check a few frames\n",
        "mov = np.array(stackRaw['stackRaw_pmc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mVK735SmQYu"
      },
      "source": [
        "#numpy function to flip the x and y for whole movie array\n",
        "flip = np.transpose(mov, axes = (0,2,1))\n",
        "#show the 500th frame\n",
        "plt.imshow(flip[500])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj9MBxjPh6lp"
      },
      "source": [
        "#save the first 500 frames back to an h5 file to test with\n",
        "#This is just for development so we don't have to wait for processing times\n",
        "#h5f = h5py.File('../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/subset_stackRaw_pmc.h5', 'w')\n",
        "#h5f.create_dataset('stackRaw_pmc', data=flip[:500])\n",
        "\n",
        "#h5f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzqeUrwjDsWg"
      },
      "source": [
        "# start a cluster\n",
        "c, dview, n_processes =\\\n",
        "    cm.cluster.setup_cluster(backend='local', n_processes=None,\n",
        "                                 single_thread=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcc1v4IOK9B6"
      },
      "source": [
        "#dview.terminate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8TzDU7qfVmB"
      },
      "source": [
        "#%% First setup some parameters for data and motion correction\n",
        "# dataset dependent parameters\n",
        "\n",
        "# ADJUSTED FROM DEFAULTS TO CARL'S PARAMS ON 11/13 (not completely)\n",
        "\n",
        "fnames = ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/210815_0/210815_0_1_stackRaw_pmc_mix1_syt_.mat'] #path to video file\n",
        "fr = 20             # imaging rate in frames per second\n",
        "decay_time = 0.4    # length of a typical transient in seconds\n",
        "dxy = (2., 2.)      # spatial resolution in x and y in (um per pixel)\n",
        "# note the lower than usual spatial resolution here\n",
        "max_shift_um = (12., 12.)       # maximum shift in um\n",
        "patch_motion_um = (100., 100.)  # patch size for non-rigid correction in um\n",
        "\n",
        "# motion correction parameters\n",
        "pw_rigid = False       # flag to select rigid vs pw_rigid motion correction\n",
        "# maximum allowed rigid shift in pixels\n",
        "max_shifts = [int(a/b) for a, b in zip(max_shift_um, dxy)]\n",
        "# start a new patch for pw-rigid motion correction every x pixels\n",
        "strides = tuple([int(a/b) for a, b in zip(patch_motion_um, dxy)])\n",
        "# overlap between pathes (size of patch in pixels: strides+overlaps)\n",
        "overlaps = (24, 24)\n",
        "# maximum deviation allowed for patch with respect to rigid shifts\n",
        "max_deviation_rigid = 3\n",
        "\n",
        "opts = params.CNMFParams()\n",
        "\n",
        "opts.set('motion', {\n",
        "    'fnames': fnames,\n",
        "    'fr': fr,\n",
        "    'decay_time': decay_time,\n",
        "    'dxy': dxy,\n",
        "    'pw_rigid': pw_rigid,\n",
        "    'max_shifts': max_shifts,\n",
        "    'strides': strides,\n",
        "    'overlaps': overlaps,\n",
        "    'max_deviation_rigid': max_deviation_rigid,\n",
        "    'border_nan': 'copy'\n",
        "    #'var_name_hdf5': 'stackRaw_pmc'\n",
        "})\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLzfCy0wFb-g"
      },
      "source": [
        "# set up some parameters for extraction\n",
        "fnames = ['../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/210815_0/210815_0_1_stackRaw_pmc_mix1_syt_.mat']\n",
        "                        # file(s) to be analyzed\n",
        "is_patches = True       # flag for processing in patches or not\n",
        "fr = 20                 # approximate frame rate of data\n",
        "decay_time = .4        # length of transient\n",
        "\n",
        "if is_patches:          # PROCESS IN PATCHES AND THEN COMBINE\n",
        "    rf = 25             # half size of each patch\n",
        "    stride = 5          # overlap between patches\n",
        "    K = 3               # number of components in each patch\n",
        "else:                   # PROCESS THE WHOLE FOV AT ONCE\n",
        "    rf = None           # setting these parameters to None\n",
        "    stride = None       # will run CNMF on the whole FOV\n",
        "    K = 40              # number of neurons expected (in the whole FOV)\n",
        "\n",
        "gSig = [6, 6]           # expected half size of neurons\n",
        "merge_thresh = 0.95     # merging threshold, max correlation allowed\n",
        "p = 0                   # order of the autoregressive system\n",
        "gnb = 2                 # global background order\n",
        "\n",
        "var_name_hdf5 = 'stackRaw_pmc' #variable to path caiman into the subfolder within our mat files\n",
        "\n",
        "opts.set('data', {'fnames': fnames,\n",
        "                   'fr': fr,\n",
        "                   'decay_time': decay_time,\n",
        "                   'rf': rf,\n",
        "                   'stride': stride,\n",
        "                   'K': K,\n",
        "                   'gSig': gSig,\n",
        "                   'merge_thr': merge_thresh,\n",
        "                   'p': p,\n",
        "                   'nb': gnb\n",
        "                   #'var_name_hdf5': var_name_hdf5\n",
        "                  })\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JAZz7VSWsEd"
      },
      "source": [
        "# %% COMPONENT EVALUATION\n",
        "# the components are evaluated in three ways:\n",
        "#   a) the shape of each component must be correlated with the data\n",
        "#   b) a minimum peak SNR is required over the length of a transient\n",
        "#   c) each shape passes a CNN based classifier (this will pick up only neurons\n",
        "#           and filter out active processes)\n",
        "\n",
        "min_SNR = 2      # peak SNR for accepted components (if above this, acept)\n",
        "rval_thr = 0.95     # space correlation threshold (if above this, accept)\n",
        "use_cnn = True      # use the CNN classifier\n",
        "min_cnn_thr = 0.90  # if cnn classifier predicts below this value, reject\n",
        "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n",
        "\n",
        "opts.set('quality', {'min_SNR': min_SNR,\n",
        "                                'rval_thr': rval_thr,\n",
        "                                'use_cnn': use_cnn,\n",
        "                                'min_cnn_thr': min_cnn_thr,\n",
        "                                'cnn_lowest': cnn_lowest})\n",
        "\n",
        "#cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdscDTVLZKBe"
      },
      "source": [
        "#THIS FUCKING LINE IS ALL IT TOOK\n",
        "#THE MOTION PARAMS DOES NOT PULL IN THE VAR NAME BY DEFAULT\n",
        "#NEEDS TO BE MANUALLY INJECTED SO IT GETS PULLED INTO MOTION CORRECT WITH THE REST\n",
        "\n",
        "opts.motion['var_name_hdf5'] = 'stackRaw_pmc'\n",
        "opts.data['var_name_hdf5'] = 'stackRaw_pmc'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VLpbI7xvI6b"
      },
      "source": [
        "The 2 lines below initiate and then run the caiman motion correction, deconvolution, and ROI evaluation by calling the fit_file function.\n",
        "\n",
        "Pasting the source code of fit_file here for transparency: \n",
        "\n",
        "\n",
        "def fit_file(self, motion_correct=False, indices=None, include_eval=False):\n",
        "\n",
        "        This method packages the analysis pipeline (motion correction, memory\n",
        "        mapping, patch based CNMF processing and component evaluation) in a\n",
        "        single method that can be called on a specific (sequence of) file(s).\n",
        "        It is assumed that the CNMF object already contains a params object\n",
        "        where the location of the files and all the relevant parameters have\n",
        "        been specified. The method will perform the last step, i.e. component\n",
        "        evaluation, if the flag \"include_eval\" is set to `True`.\n",
        "\n",
        "        Args:\n",
        "            motion_correct (bool)\n",
        "                flag for performing motion correction\n",
        "            indices (list of slice objects)\n",
        "                perform analysis only on a part of the FOV\n",
        "            include_eval (bool)\n",
        "                flag for performing component evaluation\n",
        "        Returns:\n",
        "            cnmf object with the current estimates\n",
        "\n",
        "\n",
        "        if indices is None:\n",
        "            indices = (slice(None), slice(None))\n",
        "        fnames = self.params.get('data', 'fnames')\n",
        "        if os.path.exists(fnames[0]):\n",
        "            _, extension = os.path.splitext(fnames[0])[:2]\n",
        "            extension = extension.lower()\n",
        "        else:\n",
        "            logging.warning(\"Error: File not found, with file list:\\n\" + fnames[0])\n",
        "            raise Exception('File not found!')\n",
        "\n",
        "        base_name = pathlib.Path(fnames[0]).stem + \"_memmap_\"\n",
        "        if extension == '.mmap':\n",
        "            fname_new = fnames[0]\n",
        "            Yr, dims, T = mmapping.load_memmap(fnames[0])\n",
        "            if np.isfortran(Yr):\n",
        "                raise Exception('The file should be in C order (see save_memmap function)')\n",
        "        else:\n",
        "            if motion_correct:\n",
        "                mc = MotionCorrect(fnames, dview=self.dview, **self.params.motion)\n",
        "                mc.motion_correct(save_movie=True)\n",
        "                fname_mc = mc.fname_tot_els if self.params.motion['pw_rigid'] else mc.fname_tot_rig\n",
        "                if self.params.get('motion', 'pw_rigid'):\n",
        "                    b0 = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
        "                                            np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
        "                    self.estimates.shifts = [mc.x_shifts_els, mc.y_shifts_els]\n",
        "                else:\n",
        "                    b0 = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)\n",
        "                    self.estimates.shifts = mc.shifts_rig\n",
        "                # TODO - b0 is currently direction inspecific, which can cause\n",
        "                # sub-optimal behavior. See\n",
        "                # https://github.com/flatironinstitute/CaImAn/pull/618#discussion_r313960370\n",
        "                # for further details.\n",
        "                # b0 = 0 if self.params.get('motion', 'border_nan') is 'copy' else 0\n",
        "                b0 = 0\n",
        "                fname_new = mmapping.save_memmap(fname_mc, base_name=base_name, order='C',\n",
        "                                                 border_to_0=b0)\n",
        "            else:\n",
        "                fname_new = mmapping.save_memmap(fnames, base_name=base_name, order='C')\n",
        "            Yr, dims, T = mmapping.load_memmap(fname_new)\n",
        "\n",
        "        images = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
        "        self.mmap_file = fname_new\n",
        "        if not include_eval:\n",
        "            return self.fit(images, indices=indices)\n",
        "\n",
        "        fit_cnm = self.fit(images, indices=indices)\n",
        "        Cn = summary_images.local_correlations(images[::max(T//1000, 1)], swap_dim=False)\n",
        "        Cn[np.isnan(Cn)] = 0\n",
        "        fit_cnm.save(fname_new[:-5]+'_init.hdf5')\n",
        "        #fit_cnm.params.change_params({'p': self.params.get('preprocess', 'p')})\n",
        "        # RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution\n",
        "        cnm2 = fit_cnm.refit(images, dview=self.dview)\n",
        "        cnm2.estimates.evaluate_components(images, cnm2.params, dview=self.dview)\n",
        "        # update object with selected components\n",
        "        #cnm2.estimates.select_components(use_object=True)\n",
        "        # Extract DF/F values\n",
        "        cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)\n",
        "        cnm2.estimates.Cn = Cn\n",
        "        cnm2.save(cnm2.mmap_file[:-4] + 'hdf5')\n",
        "\n",
        "        cluster.stop_server(dview=self.dview)\n",
        "        log_files = glob.glob('*_LOG_*')\n",
        "        for log_file in log_files:\n",
        "            os.remove(log_file)\n",
        "\n",
        "        return cnm2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXiK-nRtE1W-"
      },
      "source": [
        "%%capture\n",
        "# %% Now RUN CaImAn Batch (CNMF)\n",
        "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
        "cnm = cnm.fit_file(motion_correct = True, include_eval=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElmK1O9ijXSv"
      },
      "source": [
        "These cells only work if the fit function has gone through without errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chmt34wkHD9j"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dims = [128, 256]\n",
        "#5th component\n",
        "plt.figure() \n",
        "plt.imshow(np.reshape(cnm.estimates.A[:,4].toarray(), dims, order='F'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSllkGeSHg5p"
      },
      "source": [
        "#deconvolved trace for 5th component\n",
        "plt.figure() \n",
        "plt.plot(cnm.estimates.C[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN01-lViHo-x"
      },
      "source": [
        "#inferred spikes for 5th component\n",
        "plt.figure() \n",
        "plt.plot(cnm.estimates.S[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kPwxqrhHVz9"
      },
      "source": [
        "#returns a list of our binary masks\n",
        "M = cnm.estimates.A > 0\n",
        "masks = [np.reshape(M[:,i].toarray(), dims, order='F') for i in range(M.shape[1])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWFiTd5BasID"
      },
      "source": [
        "M.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYTgb7e_JGro"
      },
      "source": [
        "#plot mask for 3rd ROI\n",
        "plt.imshow(np.reshape(masks[4], dims, order='F'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd2hl39cPV1K"
      },
      "source": [
        "# %% STOP CLUSTER and clean up log files\n",
        "cm.stop_server(dview=dview)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxF1QD6NIDdM"
      },
      "source": [
        "np.reshape(cnm.estimates.A[:,4].toarray(), dims, order='F').shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doIeJer5qD0Q"
      },
      "source": [
        "# **Lauren**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta7QGapvo6wc"
      },
      "source": [
        "#%% restart cluster to clean up memory\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBs2hti7yd3F"
      },
      "source": [
        "#### Memory mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcAi_yYYmcpX"
      },
      "source": [
        "\n",
        "fname_new = cm.save_memmap(fnames, base_name='memmap_',\n",
        "                               order='C', border_to_0=0, dview=dview)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFVB_QuBk0Q6"
      },
      "source": [
        "# load memory mappable file\n",
        "Yr, dims, T = cm.load_memmap(fname_new)\n",
        "images = Yr.T.reshape((T,) + dims, order='F')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I64ruCbGn_Re"
      },
      "source": [
        "# Compute some summary images (correlation and peak to noise) while downsampling temporally 5x to speedup the process and avoid memory overflow\n",
        "cn_filter, pnr = cm.summary_images.correlation_pnr(images[::5], gSig=3, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRUoSwybk0XF"
      },
      "source": [
        "#Plot the results of the correlation/PNR projection\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(2, 2, 1); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
        "plt.subplot(2, 2, 2); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD6dRC2_onJi"
      },
      "source": [
        "#%% plot contours of found components\n",
        "Cn = cm.local_correlations(images.transpose((0,2,1)))\n",
        "Cn[np.isnan(Cn)] = 0\n",
        "plt.figure(); crd = plot_contours(img=Cn, thr=0.9)\n",
        "plt.title('Contour plots of found components')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvaZb_HWyK1D"
      },
      "source": [
        "#### Inspecting the results\n",
        "Briefly inspect the results by plotting contours of identified components against correlation image. The results of the algorithm are stored in the object `cnm.estimates`. More information can be found in the definition of the estimates object and in the wiki."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH29xxD9xBPl"
      },
      "source": [
        "#%% plot contours of found components\n",
        "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
        "Cn[np.isnan(Cn)] = 0\n",
        "cnm.estimates.plot_contours_nb(img=Cn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHy4jpYnzpJp"
      },
      "source": [
        "#%% plot contour plots of accepted and rejected components\n",
        "cnm.estimates.plot_contours_nb(img=cn_filter, idx=cnm.estimates.idx_components)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ouQSjZd0EZw"
      },
      "source": [
        "cnm.estimates.hv_view_components(img=cn_filter, idx=cnm.estimates.idx_components,\n",
        "                                denoised_color='red', cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPC4MxvmonLt"
      },
      "source": [
        "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
        "\n",
        "print(' ***** ')\n",
        "print('Number of total components: ', len(cnm.estimates.C))\n",
        "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyKglYCjIDf0"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#How many neurons to plot\n",
        "neuronsToPlot = 20\n",
        "\n",
        "DeconvTraces = cnm.estimates.S\n",
        "RawTraces = cnm.estimates.C\n",
        "SFP = cnm.estimates.A\n",
        "SFP_dims = list(dims)\n",
        "SFP_dims.append(SFP.shape[1]) \n",
        "print('Spatial foootprints dimensions (height x width x neurons): ' + str(SFP_dims))\n",
        "\n",
        "numNeurons = SFP_dims[2]\n",
        "\n",
        "SFP = np.reshape(SFP.toarray(), SFP_dims, order='F')\n",
        "\n",
        "maxRawTraces = np.amax(RawTraces)\n",
        "\n",
        "plt.figure(figsize=(30,15))\n",
        "plt.subplot(341);\n",
        "## plt.subplot(345); plt.plot(mc.shifts_rig); plt.title('Motion corrected shifts')\n",
        "plt.subplot(3,4,9);\n",
        "plt.subplot(3,4,2); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
        "plt.subplot(3,4,6); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')\n",
        "plt.subplot(3,4,10); plt.imshow(np.amax(SFP,axis=2)); plt.colorbar(); plt.title('Spatial footprints')\n",
        "\n",
        "plt.subplot(2,2,2); plt.figure; plt.title('Example traces (first 50 cells)')\n",
        "plot_gain = 10 # To change the value gain of traces\n",
        "if numNeurons >= neuronsToPlot:\n",
        "  for i in range(neuronsToPlot):\n",
        "    if i == 0:\n",
        "      plt.plot(RawTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = RawTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "else:\n",
        "  for i in range(numNeurons):\n",
        "    if i == 0:\n",
        "      plt.plot(RawTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = RawTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "\n",
        "plt.subplot(2,2,4); plt.figure; plt.title('Deconvolved traces (first 50 cells)')\n",
        "plot_gain = 20 # To change the value gain of traces\n",
        "if numNeurons >= neuronsToPlot:\n",
        "  for i in range(neuronsToPlot):\n",
        "    if i == 0:\n",
        "      plt.plot(DeconvTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = DeconvTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "else:\n",
        "  for i in range(numNeurons):\n",
        "    if i == 0:\n",
        "      plt.plot(DeconvTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = DeconvTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')      \n",
        "\n",
        "# Save summary figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAKTh1vyx_2g"
      },
      "source": [
        "%%capture\n",
        "#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
        "cnm2 = cnm.refit(images, dview=dview)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qoa66me30vVT"
      },
      "source": [
        "cnm.estimates.play_movie(images, q_max=99.5, magnification=2,\n",
        "                                 include_bck=True, gain_res=10, bpx=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1a45fQ3b_ax"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlT2UQyX33ih"
      },
      "source": [
        "#path to manual ROI file provided by Carl\n",
        "!ls ../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/manualROIs_fixed/210815_0_1_manualROIs_mix1_syt.mat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PtupBe44jb-"
      },
      "source": [
        "g = h5py.File('../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/manualROIs_fixed/210815_0_1_manualROIs_mix1_syt.mat', 'r')\n",
        "#current shape\n",
        "g['bwMaskStack'][:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtL7W9-QUYrb"
      },
      "source": [
        "#shape to match - caiman results we fit above\n",
        "cnm.estimates.A.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcRnRPZ8XfyW"
      },
      "source": [
        "#image of original mask to match\n",
        "f = h5py.File('../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs/210815_0_1_manualROIs_mix1_syt.mat', 'r')\n",
        "plt.imshow(np.reshape(f['bwLabel'][:].T, dims, order='F'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoqGxVyAUy-i"
      },
      "source": [
        "#transpose the matrix and save to an array A\n",
        "A = g['bwMaskStack'][:].T\n",
        "\n",
        "#rearrange the dimensions and show the new shape\n",
        "A = A.transpose(1,0,2)\n",
        "A.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HokL8DvmU9Vj"
      },
      "source": [
        "#reshape to 2D, first dimension is 128*256 (32768), 2nd dimension is the # of ROI's\n",
        "A = A.reshape((A.shape[1]*A.shape[0]), A.shape[2])\n",
        "A.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG8f05HjWr2B"
      },
      "source": [
        "#Show the unique looking ROI to confirm we're not distorting ROIs\n",
        "plt.imshow(np.reshape(A[:,11], dims, order='F'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0ATz3fzWzcg"
      },
      "source": [
        "#Try running register_pair and see what happens\n",
        "matched_ROIs1, matched_ROIs2, non_matched1, non_matched2, performance, A2 = cm.base.rois.register_ROIs(A, M, dims=dims)\n",
        "performance\n",
        "#zero matches - not sure if this is because our ROI's suck or if it's a formatting problem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9w1p423YvCj"
      },
      "source": [
        "#show roi masks from caiman\n",
        "for x in range(28):\n",
        "  plt.figure()\n",
        "  plt.imshow(np.reshape(masks[x], dims, order='F'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iAyVMs_ajzB"
      },
      "source": [
        "#show masks identified by carl\n",
        "for x in range(15):\n",
        "  plt.figure()\n",
        "  plt.imshow(np.reshape(A[:,x], dims, order='F'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKPpFK8usw-5"
      },
      "source": [
        "# **Lauren** Validation\n",
        "*Adding code from separate notebook*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taDNM8fmbtps"
      },
      "source": [
        "M"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}