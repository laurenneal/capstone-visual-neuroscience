{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seeded CNMF Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DMQyPTVxwhVU",
        "fCRFFvODsO4i",
        "OzmBKC4DsV2y"
      ],
      "mount_file_id": "1rngpZ2v5WfmtxJTvHkWuQ1ZQsa8f7lz_",
      "authorship_tag": "ABX9TyNPTqtxZCzzI9K33NcYtf/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenneal/capstone-visual-neuroscience/blob/Dylan/Seeded_CNMF_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMQyPTVxwhVU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbIj2QeEAbTE",
        "outputId": "8aa205c0-d865-4f9c-a344-96811a36e644"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrE1xeswQNHM",
        "outputId": "3ee11c76-38e3-44ca-e3e9-010de4bdcb3a"
      },
      "source": [
        "# Install CaImAn - takes around 2 minutes\n",
        "\n",
        "!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "%cd '/content/CaImAn/'\n",
        "!pip install -e .\n",
        "\n",
        "# Install caiman dependencies (&> /dev/null will suppress the hundreds of printed lines in the output)\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "\n",
        "#import other dependencies\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "#IMPORTANT! Newer versions of h5py will cause errors when saving results\n",
        "!pip install h5py==2.10.0\n",
        "import h5py\n",
        "\n",
        "#Set up caiman\n",
        "!python setup.py build_ext -i\n",
        "\n",
        "#Other file setup\n",
        "!python caimanmanager.py install --inplace\n",
        "\n",
        "#Caiman imports\n",
        "import caiman as cm\n",
        "from caiman.motion_correction import MotionCorrect\n",
        "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "from caiman.utils.utils import download_demo\n",
        "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
        "from caiman.summary_images import local_correlations_movie_offline\n",
        "from scipy.ndimage import center_of_mass\n",
        "from IPython.display import display, clear_output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CaImAn'...\n",
            "remote: Enumerating objects: 24960, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 24960 (delta 0), reused 2 (delta 0), pack-reused 24954\u001b[K\n",
            "Receiving objects: 100% (24960/24960), 518.36 MiB | 28.97 MiB/s, done.\n",
            "Resolving deltas: 100% (16746/16746), done.\n",
            "Checking out files: 100% (317/317), done.\n",
            "/content/CaImAn\n",
            "Obtaining file:///content/CaImAn\n",
            "Installing collected packages: caiman\n",
            "  Running setup.py develop for caiman\n",
            "Successfully installed caiman-1.9.7\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 22.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "running build_ext\n",
            "Installed /root/caiman_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logging and configuring enviroment for interactive visualizations\n",
        "#Some of this is redundant\n",
        "\n",
        "try:\n",
        "    get_ipython().magic(u'load_ext autoreload')\n",
        "    get_ipython().magic(u'autoreload 2')\n",
        "    print(1)\n",
        "except:\n",
        "    print('NOT IPYTHON')\n",
        "\n",
        "from ipyparallel import Client\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import psutil\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import sys\n",
        "\n",
        "import caiman as cm\n",
        "from caiman.utils.visualization import nb_view_patches3d\n",
        "import caiman.source_extraction.cnmf as cnmf\n",
        "from caiman.components_evaluation import evaluate_components, estimate_components_quality_auto\n",
        "from caiman.cluster import setup_cluster\n",
        "from caiman.paths import caiman_datadir\n",
        "\n",
        "import bokeh.plotting as bpl\n",
        "bpl.output_notebook()\n",
        "\n",
        "#uncomment this to enable detailed logging for debugging\n",
        "\n",
        "# logging.basicConfig(format=\n",
        "#                           \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
        "#                     # filename=\"/tmp/caiman.log\",\n",
        "#                     level=logging.DEBUG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpFwJng10xS6",
        "outputId": "1c4ecb20-cf7a-4b52-87fa-9b950f392d7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCRFFvODsO4i"
      },
      "source": [
        "## Get paths to movie files and labelled ROI masks - this was used for our model tuning where we looped over these pairs, only here to collect these pairs to demonstate function below working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfNJcFmeEq23"
      },
      "source": [
        "# #get a list of our masks and a list of our stacks in the same order\n",
        "# from os import listdir\n",
        "# maskpath = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/manualROIs'\n",
        "# mask_filenames = [f for f in listdir(maskpath) if 'manualROIs' in f]\n",
        "# mask_filenames = sorted(mask_filenames)\n",
        "# mask_filenames"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBBLhWJoFMXP"
      },
      "source": [
        "# stack_indices = [x[:10] for x in mask_filenames] #get the index portion of the masks\n",
        "# stack_celltypes = [x[22:(len(x)-4)] for x in mask_filenames] #get the cell type descriptions\n",
        "\n",
        "# #create filenames in mat and h5, well only keep what exists\n",
        "# stack_filenames_h5 = ['CLEAN_' + stack_indices[x] + '_stackRaw_mc_' + stack_celltypes[x] \\\n",
        "#                    + '_.h5' for x in range(len(mask_filenames))] #reconstruct filenames for the movies we have masks for\n",
        "# stack_filenames_mat = ['CLEAN_' + stack_indices[x] + '_stackRaw_mc_' + stack_celltypes[x] \\\n",
        "#                    + '_.mat' for x in range(len(mask_filenames))] #reconstruct filenames for the movies we have masks for\n",
        "# stack_filenames = stack_filenames_h5 + stack_filenames_mat \n",
        "# stack_filenames"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cRs3HHyG0nV"
      },
      "source": [
        "# #checking that files exist in our cleaned file\n",
        "# stackpath = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/DATA/stackRaw/CLEANED'\n",
        "# stackfiles = [f for f in listdir(stackpath) if f in stack_filenames]\n",
        "# stackfiles = sorted(stackfiles)\n",
        "# stackfiles"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkrZMX_oLZ8J"
      },
      "source": [
        "# #convert filenames back into paths\n",
        "# maskpaths = [maskpath+'/'+f for f in mask_filenames]\n",
        "# stackpaths = [stackpath+'/'+f for f in stackfiles]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O3Ta8XtKXFQ"
      },
      "source": [
        "# #join the lists into pairs of tuples\n",
        "# mask_stack_pairs = list(map(lambda x, y:[x,y], maskpaths, stackpaths))\n",
        "# mask_stack_pairs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzmBKC4DsV2y"
      },
      "source": [
        "## Initialize parameters object with starter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24iRFksugPTv"
      },
      "source": [
        "#create parameters object\n",
        "opts = params.CNMFParams()\n",
        "#fname will be assigned in the loop\n",
        "fnames = []\n",
        "subfolder = 'stackRaw_mc'\n",
        "opts.motion['var_name_hdf5'] = subfolder\n",
        "opts.data['var_name_hdf5'] = subfolder"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLzfCy0wFb-g"
      },
      "source": [
        "# set initial values for extraction and evaluation\n",
        "# most of these are specific to our data and will not need to be changed during optimization\n",
        "\n",
        "# overall params about our data\n",
        "\n",
        "fr = 20                 # approximate frame rate of data - CONFIRMED FPS\n",
        "decay_time = .4         # length of transient - CONFIRMED APPROPRIATE FOR OUR INDICATOR GCaMP6f\n",
        "dims = [128, 256]       # dimensions of the FOV in pixels - CONFIRMED\n",
        "dxy = [.29, .29]        # resolution of 1 pixel in um - CONFIRMED BY CARL\n",
        "\n",
        "opts.set('data', {'fnames': fnames,\n",
        "                   'fr': fr,\n",
        "                   'decay_time': decay_time,\n",
        "                   'dims': dims,\n",
        "                   'dxy': dxy\n",
        "                  })\n",
        "\n",
        "\n",
        "# params related to the temporal traces\n",
        "\n",
        "p = 0                   # order of the autoregressive system - 0 from carl's code\n",
        "fudge_factor = 1        # (default is 0.96; Carl's value = 1) -- bias correction factor for discrete time constants\n",
        "ITER = 2                # (default is 2; Carl's value=5) -- block coordinate descent iterations\n",
        "tnb = 1                  # temporal global background components - TUNE\n",
        "\n",
        "opts.set('temporal', {'p': p,\n",
        "                      'fudge_factor': fudge_factor,\n",
        "                      'ITER': ITER#,\n",
        "                      #'nb': tnb\n",
        "                 })\n",
        "\n",
        "# p is also set in the preprocessing step\n",
        "opts.set('preprocess', {'p': p\n",
        "                 })\n",
        "\n",
        "\n",
        "\n",
        "# params related to the FOV and patches for parallel processing\n",
        "\n",
        "is_patches = False      # flag for processing in patches or not - turn on or off - Not used in Matlab\n",
        "\n",
        "if is_patches:          # PROCESS IN PATCHES AND THEN COMBINE \n",
        "    rf = 25             # half size of each patch \n",
        "    stride = 5          # overlap between patches \n",
        "    K = 3               # number of components in each patch\n",
        "    p_patch = p\n",
        "\n",
        "else:                   # PROCESS THE WHOLE FOV AT ONCE\n",
        "    rf = None           # setting these parameters to None\n",
        "    stride = None       # will run CNMF on the whole FOV \n",
        "    K = 30              # number of neurons expected (in the whole FOV) - 40 from Carl's Code, seems to be too many\n",
        "\n",
        "n_processes = 2         # Number of processes to run in parallel, 2 for 2 cores available in Colab\n",
        "\n",
        "opts.set('patch', {'rf': rf,\n",
        "                   'stride': stride,\n",
        "                   'n_processes': n_processes,\n",
        "                   \"K\": K\n",
        "                  })   \n",
        "\n",
        "\n",
        "\n",
        "# initialization params\n",
        "ssub = 3               # spatial downsampling\n",
        "tsub = 1                # temporal downsampling\n",
        "ssub_B = 3              # background spatial downsampling\n",
        "gSig = [5,5]            # radius (half-size) of average neurons (in pixels)\n",
        "tau=0                   # standard deviation of neuron size along x and y - from Carl's code\n",
        "nb = 1                  # number of background components\n",
        "method_init = 'greedy_roi' #python Caiman defaults to greedy_roi, carl's code uses sparse_nmf, but sparse_nmf runs MUCH slower\n",
        "\n",
        "opts.set('init', {'K': K,            # declared above in patch params    \n",
        "                   'tau': tau,      \n",
        "                   'tsub': tsub, \n",
        "                   'ssub': ssub, \n",
        "                   'ssub_B': ssub_B, \n",
        "                   'nb': nb,\n",
        "                   'method_init': method_init\n",
        "                  })\n",
        "\n",
        "# parameters related to merging correlated ROIs\n",
        "merge_thr = 0.95     # merging threshold, max correlation allowed - From Carl's Code\n",
        "\n",
        "opts.set('merging', {'merge_thr': merge_thr\n",
        "                            })\n",
        "\n",
        "\n",
        "#set some spatial params\n",
        "snb = 1                  # spatial global background components\n",
        "\n",
        "opts.set('spatial', {'nb': snb\n",
        "                            })\n",
        "\n",
        "# %% COMPONENT EVALUATION\n",
        "# the components are evaluated in three ways:\n",
        "#   a) the shape of each component must be correlated with the data\n",
        "#   b) a minimum peak SNR is required over the length of a transient\n",
        "#   c) each shape passes a CNN based classifier (this will pick up only neurons\n",
        "#           and filter out active processes)\n",
        "\n",
        "\n",
        "#Not sure if these should be tuned or not\n",
        "\n",
        "min_SNR = 2.5      # peak SNR for accepted components (if above this, acept)\n",
        "SNR_lowest = 1         # minimum SNR for accepted components (if below this, reject)\n",
        "rval_thr = 0.9     # space correlation threshold (if above this, accept)\n",
        "\n",
        "use_cnn = True      # use the CNN classifier affects if 2 below params are used\n",
        "min_cnn_thr = 0.9  # if cnn classifier predicts below this value, reject\n",
        "cnn_lowest = 0.1   # neurons with cnn probability lower than this value are rejected\n",
        "\n",
        "opts.set('quality', {'min_SNR': min_SNR,\n",
        "                     'SNR_lowest': SNR_lowest,\n",
        "                     'rval_thr': rval_thr,\n",
        "                     'use_cnn': use_cnn,\n",
        "                     'min_cnn_thr': min_cnn_thr,\n",
        "                     'cnn_lowest': cnn_lowest})\n",
        "\n",
        "\n",
        "#Manually assign subfolder variable\n",
        "opts.motion['var_name_hdf5'] = subfolder\n",
        "opts.data['var_name_hdf5'] = subfolder\n",
        "\n",
        "\n",
        "\n",
        "#motion correction not used for our parameter tuning. Leaving these params here in case they get used in the future.\n",
        "\n",
        "#%% First setup some parameters for data and motion correction\n",
        "# dataset dependent parameters\n",
        "\n",
        "# ADJUSTED FROM DEFAULTS TO CARL'S PARAMS ON 11/13 (not completely)\n",
        "\n",
        "fr = 20             # imaging rate in frames per second\n",
        "decay_time = 0.4    # length of a typical transient in seconds\n",
        "dxy = (.29, .29)      # spatial resolution in x and y in (um per pixel)\n",
        "max_shift_um = (12., 12.)       # maximum shift in um\n",
        "patch_motion_um = (100., 100.)  # patch size for non-rigid correction in um\n",
        "\n",
        "# motion correction parameters\n",
        "pw_rigid = False       # flag to select rigid vs pw_rigid motion correction\n",
        "# maximum allowed rigid shift in pixels\n",
        "max_shifts = [int(a/b) for a, b in zip(max_shift_um, dxy)]\n",
        "# start a new patch for pw-rigid motion correction every x pixels\n",
        "strides = tuple([int(a/b) for a, b in zip(patch_motion_um, dxy)])\n",
        "# overlap between pathes (size of patch in pixels: strides+overlaps)\n",
        "overlaps = (24, 24)\n",
        "# maximum deviation allowed for patch with respect to rigid shifts\n",
        "max_deviation_rigid = 3\n",
        "\n",
        "opts.set('motion', {\n",
        "    'fnames': fnames,\n",
        "    'fr': fr,\n",
        "    'decay_time': decay_time,\n",
        "    'dxy': dxy,\n",
        "    'pw_rigid': pw_rigid,\n",
        "    'max_shifts': max_shifts,\n",
        "    'strides': strides,\n",
        "    'overlaps': overlaps,\n",
        "    'max_deviation_rigid': max_deviation_rigid,\n",
        "    'border_nan': 'copy'\n",
        "})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seed CNMF with the masks"
      ],
      "metadata": {
        "id": "UEtM1AAmtvYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to run seeded cnmf using masks, then return results\n",
        "\n",
        "def seeded_cnmf(path_to_stack, path_to_masks, opts):\n",
        "  import warnings\n",
        "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "  fnames = [path_to_stack]\n",
        "  opts.set('data', {'fnames': fnames})\n",
        "\n",
        "  try:\n",
        "\n",
        "    #cluster handling\n",
        "    if 'dview' in locals():\n",
        "      cm.stop_server(dview=dview)\n",
        "    dview = cm.cluster.start_server(ncpus=2) #Start a cluster with 2 CPU's (available in colab)\n",
        "\n",
        "\n",
        "    #Read in masks and reformat\n",
        "    g = h5py.File(path_to_masks, 'r')\n",
        "\n",
        "    #transpose the matrix and save to an array A\n",
        "    mask_A = g['bwMaskStack'][:].T\n",
        "\n",
        "    #close the .mat file holding the masks\n",
        "    g.close()\n",
        "\n",
        "    #rearrange the dimensions of masks to match reformatted .h5 movie that has been flipped (not necessary if input movie has not been flipped), \n",
        "                                                                                                                  #but will afect following lines\n",
        "    mask_A = mask_A.transpose(1,0,2)\n",
        "\n",
        "    #reshape to 2D, first dimension is 128*256 (32768), 2nd dimension is the # of ROI's\n",
        "    mask_A = mask_A.reshape((mask_A.shape[1]*mask_A.shape[0]), mask_A.shape[2])\n",
        "\n",
        "    #convert the values from 0/1 to boolean False/True\n",
        "    mask_A = np.array(mask_A, dtype=bool)\n",
        "    print('mask read in and reformatted')\n",
        "\n",
        "    #For seeded CNMF, need to verify certain params\n",
        "    opts.patch['only_init'] = False\n",
        "    opts.data['use_cnn'] = False\n",
        "\n",
        "    print('params adjusted for seeded cnmf')\n",
        "    \n",
        "    #Initialize a new cnmf object and pass in our masks as the \"Ain\" param\n",
        "    #\"Ain\" is A-in, meaning the A matrix holding the spatial footprints of the roi's\n",
        "    cnm_seeded = cnmf.CNMF(n_processes = 2, params=opts, dview=dview, Ain=mask_A)\n",
        "    print('seeded cnmf object initialized')\n",
        "    cnm_seeded.fit_file(motion_correct = False, include_eval=True)\n",
        "    print('seeded cnmf completed')\n",
        "\n",
        "    cm.stop_server(dview=dview)\n",
        "\n",
        "\n",
        "#Comment out whichever you don't want to return and leave the one you do\n",
        "\n",
        "    #return either the whole fit CNMF object(with associated visualizations available)\n",
        "    #return cnm_seeded\n",
        "\n",
        "    #Or just return the spatial and temporal response (A and C matrices) in a dictionary, to be saved and used in our model\n",
        "    return {'stack_name': path_to_stack[:(len(path_to_stack)-4)].split('/')[6], #chops the movie identifier out of the filepath\n",
        "            'spatial': cnm_seeded.estimates.A,\n",
        "            'temporal': cnm_seeded.estimates.C}\n",
        "\n",
        "  except:\n",
        "    print('failed')\n",
        "    cm.stop_server(dview=dview)"
      ],
      "metadata": {
        "id": "htsfa6hetzxG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#manually setting the paths to the example files in the new folder\n",
        "#later we can pass these in with a wrapper function to extract everything in the folders\n",
        "\n",
        "path_to_stack = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded CNMF/Preformatted Movies/EXAMPLE_210728_0_1_stackRaw_mc_tm2_tm9_syt_.h5'\n",
        "path_to_masks = '../drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded CNMF/Seed Masks/EXAMPLE_210728_0_1_manualROIs_tm2_tm9_syt.mat'"
      ],
      "metadata": {
        "id": "Dj6moakNsRot"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Call the function, passing in a string path to the movie, path to masks, and the params object('opts')\n",
        "\n",
        "seeded = seeded_cnmf(path_to_stack = path_to_stack, #from the pairs of files above, could be swapped out for string directly\n",
        "                     path_to_masks = path_to_masks, #same as above\n",
        "                     opts = opts) #params object globally initialized earlier\n",
        "\n",
        "#uncomment this line if returning the full object to visualize\n",
        "#seeded.estimates.nb_view_components(denoised_color = 'red')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do8pyatDvxdE",
        "outputId": "4fbbfa7d-eee9-4807-c2fa-35c42864f4f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
            "...............mask read in and reformatted\n",
            "params adjusted for seeded cnmf\n",
            "seeded cnmf object initialized\n",
            "spatial support for each components given by the user\n",
            "USING MODEL:/root/caiman_data/model/cnn_model.json\n",
            "1/1 [==============================] - 0s 477ms/step\n",
            "....seeded cnmf completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test output dictionary and save - this will all not run if the function output above is edited to output the cnmf object for visualization"
      ],
      "metadata": {
        "id": "LFfx8GgkzLMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check the stack name saved in the dictionary\n",
        "print(seeded['stack_name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsRWt2AEzRlG",
        "outputId": "b1ddb211-5698-4269-bf47-618b3cce8716"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXAMPLE_210728_0_1_stackRaw_mc_tm2_tm9_syt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#temporal responses are saved in the dictionary under 'temporal'\n",
        "#showing shape here just for demonstration\n",
        "seeded['temporal'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDj7Djm_4GAe",
        "outputId": "192a8e8a-801c-4e96-b1bd-093aff885359"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 5519)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#spatial footprints are saved in the dictionary under 'spatial'\n",
        "seeded['spatial'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oHMzcz44R5t",
        "outputId": "401926ae-bbaf-41c7-967e-98515b88a6aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32768, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#procedurally generate the path to the result file we will write\n",
        "results_folder_path ='/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded CNMF/Results/'\n",
        "result_h5_path = results_folder_path + seeded['stack_name'] + '_result.h5'\n",
        "result_h5_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S0vUdtOT6c-t",
        "outputId": "5bddc34e-7821-4781-96e4-6c2eeca01d81"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded CNMF/Results/EXAMPLE_210728_0_1_stackRaw_mc_tm2_tm9_syt_result.h5'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write the results into an hdf5 file\n",
        "with h5py.File(result_h5_path, \"w\") as result_file:\n",
        "  result_file.create_dataset('stack_name', data=seeded['stack_name'])\n",
        "  result_file.create_dataset('temporal', data=seeded['temporal'])\n",
        "  result_file.create_dataset('spatial', data=seeded['spatial'].A) # \".A\" converts from a sparse matrix to normal. h5py cant save sparse matrices\n"
      ],
      "metadata": {
        "id": "rfRpyz-b0YiE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read those results back to test\n",
        "results_read = h5py.File(result_h5_path,'r')\n",
        "results_read.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1etRWOBr5UmN",
        "outputId": "514ebb0f-d491-417c-c5b6-5e70abe5285e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KeysViewHDF5 ['spatial', 'stack_name', 'temporal']>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verify that everything wrote to the file is identical to the original results\n",
        "print(results_read['spatial'][:].all() == seeded['spatial'].A.all())\n",
        "print(results_read['temporal'][:].all() == seeded['temporal'].all())\n",
        "print(results_read['stack_name'][()] == seeded['stack_name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRUSYOLf5AQD",
        "outputId": "bfaa2fd6-7bbd-43f2-cb82-42f433f43119"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#close the results file\n",
        "results_read.close()"
      ],
      "metadata": {
        "id": "jA2HX8KQ8BnQ"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}