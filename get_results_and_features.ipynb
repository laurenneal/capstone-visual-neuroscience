{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_results_and_features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenneal/capstone-visual-neuroscience/blob/Jordan/get_results_and_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response and Stimulus"
      ],
      "metadata": {
        "id": "f9gUoDRpDnn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#imports\n",
        "!pip install hdf5storage\n",
        "import hdf5storage \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from tqdm import notebook\n",
        "from more_itertools import sliced\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFsKVY1z-HyU",
        "outputId": "bd2c784b-93f1-4a2d-d512-9afda1f48914"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting hdf5storage\n",
            "  Downloading hdf5storage-0.1.18-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n",
            "Installing collected packages: hdf5storage\n",
            "Successfully installed hdf5storage-0.1.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DOO3m2Ct7eT6"
      },
      "outputs": [],
      "source": [
        "#This file contains the response and stimulus data for all stacks of this movie\n",
        "#The file is named using the first stack in the file, but it contains the other stacks, \n",
        "#like 210815_0_2_stim_mc_mix1_syt_, 210815_0_3_stim_mc_mix1_syt_, etc, as well\n",
        "\n",
        "path = '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Stimulus_Features/210815_0_1_stim_mc_mix1_syt_.mat'\n",
        "#read file in using hdf5 structure\n",
        "results_file = hdf5storage.loadmat(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list the two main folders\n",
        "list(results_file.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_OOc7mIChoL",
        "outputId": "c508ff2d-f0cc-4500-94dc-b61cfee8170f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['resp', 'stim1']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the response and stimulus are now in a 1x(number of stacks) matrix\n",
        "results_file['resp'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuQwuDnEjvfr",
        "outputId": "49ef9d8a-eb2d-4269-8dd8-f6161597a05d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#each stack has a (# of rois) by (# of frames) matrix holding the fluorescence trace of the rois in that stack\n",
        "for x in results_file['resp'][0]:\n",
        "  print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2XBAJbAmsZy",
        "outputId": "08fe9e08-0545-44e7-ab6b-cc81816815af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 881)\n",
            "(15, 3524)\n",
            "(15, 5286)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#same for the stimulus values\n",
        "for x in results_file['stim1'][0]:\n",
        "  print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27Py8oa6j0X3",
        "outputId": "6af734ba-b759-4694-c0e3-13b08ba33e52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 5286)\n",
            "(15, 881)\n",
            "(15, 3524)\n",
            "(15, 5286)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V97S4G3mxd_m",
        "outputId": "50206eba-1235-4d2b-d245-27ae77f76491"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210815_0_10_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_1_label_mc_mix1_syt_.csv\n",
            "210815_0_1_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_2_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_3_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_4_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_5_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_6_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_7_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_8_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n",
            "210815_0_9_stackRaw_mc_mix1_syt_result_20220213T070259.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything below this line needs to be reworked to run on the new format.\n",
        "\n",
        "The spatial footprints are stored in the original 'results' folder that we need to path to, but the stimulus and response are stored together in the new format\n",
        "\n",
        "Also need to use the filename, stack index, and roi index to create a unique identifier for each roi by stack"
      ],
      "metadata": {
        "id": "nXtTL_EQLJ8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "root = 'drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/'\n",
        "spatial_files = os.listdir(root)\n",
        "spatial_files = [s for s in spatial_files if s[-3:] == '.h5']\n",
        "spatial_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La_mLJiEqdGv",
        "outputId": "273d5f9b-73c9-4dd3-e994-ae0a9a848140"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['210815_0_1_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_2_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_3_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_4_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_5_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_6_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_7_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_8_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_9_stackRaw_mc_mix1_syt_result_20220213T070259.h5',\n",
              " '210815_0_10_stackRaw_mc_mix1_syt_result_20220213T070259.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rois = pd.DataFrame(columns=['stack','roi','spatial','temporal'])"
      ],
      "metadata": {
        "id": "QKl172xxr8ui"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h5py.File(root + spatial_files[0],'r')['spatial'][:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ2iRn26tVWX",
        "outputId": "2c90d976-6c58-411b-c555-76b195d8a56c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 32768)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h5py.File(root + spatial_files[0],'r')['temporal'][:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77252k5gZgbB",
        "outputId": "a92793cf-c20a-4db3-c5fd-70596295c588"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 5519)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for f in enumerate(spatial_files): # the shapes above don't match up\n",
        "  df = pd.DataFrame({\n",
        "      'stack': f,\n",
        "      'roi': , # use range to make a list for the numerb of rois\n",
        "      'spatial': h5py.File(root + f,'r')['spatial'][:],\n",
        "      'temporal': h5py.File(root + f,'r')['temporal'][:]\n",
        "  })"
      ],
      "metadata": {
        "id": "MCGtFbYmmfS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stack of each roi's footprints - we'll use each of these\n",
        "bwLabelStack = results_file['spatial']\n",
        "\n",
        "bwLabelStack.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "brH61k4LKdCE",
        "outputId": "ce769b79-3cf9-4763-bb6d-ee8fb835359e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-65cde8735c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# stack of each roi's footprints - we'll use each of these\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbwLabelStack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spatial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbwLabelStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'spatial'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_file.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrY0ucAXi6iS",
        "outputId": "a09257e5-efb4-4156-a48c-b7c24b7700ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['resp', 'stim1'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rois = "
      ],
      "metadata": {
        "id": "gKBy_6TUmA4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #plot the first roi\n",
        "# dims = [128, 256]\n",
        "# #save to variable\n",
        "# spatial = bwLabelStack[0][:]\n",
        "# plt.imshow(np.reshape(spatial, dims, order=\"F\"))"
      ],
      "metadata": {
        "id": "t16V6DX8kUPq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #visualize temporal traces - first roi\n",
        "# temporal = results_file['temporal'][0]\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.plot(temporal)"
      ],
      "metadata": {
        "id": "9y2WO04ILSdc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell type labels"
      ],
      "metadata": {
        "id": "t2wTh-GKn498"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# label_csv = pd.read_csv('/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_1_label_mc_mix1_syt_.csv')\n",
        "# label_csv"
      ],
      "metadata": {
        "id": "Xph1uKaOn7xl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stimulus Data read and exploration"
      ],
      "metadata": {
        "id": "Ul8bF6rPq6-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stimulus_file = h5py.File(stimulus_path, 'r')\n",
        "# stimulus_file['stimulus'].shape"
      ],
      "metadata": {
        "id": "NwzJrZOvq-mA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #plot the stimulus for the first roi for the first 200 frames\n",
        "# #note that the matrix shape is flipped compared to the results matrices\n",
        "# #need to access index zero with [:,0] rather than [0]\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.plot(stimulus_file['stimulus'][:][:,0])"
      ],
      "metadata": {
        "id": "unVmi1eTugIh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract features from each roi in the file"
      ],
      "metadata": {
        "id": "ZwpFrkE3Mgzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #IMPORTANT\n",
        "# #Set the time period in frames that we want to consider here\n",
        "# #If 1, then we're doing no temporal collapsing, just taking the fluorescence / stimulus\n",
        "# #if >1, then we return the mean, min, max fluorescence over chunks of that length\n",
        "\n",
        "# temporal_period_length = 1\n",
        "\n",
        "# #every roi will have the same stack name, so declare it here\n",
        "# stack_name = results_file['stack_name'][()].decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "-3eBW_xpMi2p"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #set up different dataframes depending on if we're collpsing temporal features or not\n",
        "# if temporal_period_length == 1:\n",
        "\n",
        "#   roi_features = pd.DataFrame(columns =['roi_ID',\n",
        "#                                       'area',\n",
        "#                                       'center_of_mass_row',\n",
        "#                                       'center_of_mass_column',\n",
        "#                                       'fluorescence',\n",
        "#                                       'stimulus_demo',\n",
        "#                                       'label'])\n",
        "  \n",
        "# else:\n",
        "#   roi_features = pd.DataFrame(columns =['roi_ID',\n",
        "#                                     'area',\n",
        "#                                     'center_of_mass_row',\n",
        "#                                     'center_of_mass_column',\n",
        "#                                     'mean_fluorescence',\n",
        "#                                     'min_fluorescence',\n",
        "#                                     'max_fluorescence',\n",
        "#                                     'mean_stimulus_demo',\n",
        "#                                     'min_stimulus_demo',\n",
        "#                                     'max_stimulus_demo',\n",
        "#                                     'label'])\n",
        "  \n",
        "# #loop through rois and extract features - these have not been validated to be calculated correctly\n",
        "# for x in notebook.tqdm(range(len(bwLabelStack))):\n",
        "\n",
        "#   spatial = bwLabelStack[x] #spatial footprint of the x'th roi\n",
        "#   temporal = results_file['temporal'][x] #temporal trace of the x'th roi\n",
        "#   stimulus = stimulus_file['stimulus'][:][:,x] #stimulus feature for the x'th roi\n",
        "#   label = label_csv['label'][x] #cell type label of the x'th roi\n",
        "#   roi_ID = stack_name + str(x) #comcatenated ID for the roi - date, fly index, stack index, mix, roi index\n",
        "\n",
        "#   #calculate spatial measures\n",
        "#   area = np.sum(spatial)\n",
        "#   dims = [128,256]\n",
        "#   spatial_img = np.reshape(spatial, dims, order=\"F\")\n",
        "#   center_of_mass_row, center_of_mass_column = ndimage.center_of_mass(spatial_img)\n",
        "  \n",
        "#   #If one sample is one frame, no temporal slicing necessary\n",
        "#   if temporal_period_length == 1:\n",
        "\n",
        "#     #to loop through all frames, swap the number for len(temporal)\n",
        "#     for frame in notebook.tqdm(range(len(temporal))):\n",
        "\n",
        "#       fluorescence = temporal[frame] #loop through frames\n",
        "#       stimulus_value = stimulus[frame] #and loop through stimulus\n",
        "\n",
        "#       roi_features = roi_features.append({'roi_ID': roi_ID,\n",
        "#                                           'area': area,\n",
        "#                                           'center_of_mass_row': center_of_mass_row,\n",
        "#                                           'center_of_mass_column': center_of_mass_column,\n",
        "#                                           'fluorescence': fluorescence,\n",
        "#                                           'stimulus_demo': stimulus_value,\n",
        "#                                           'label': label}, ignore_index=True)\n",
        "      \n",
        "#   else:\n",
        "\n",
        "#     #list of lists containing the sliced up fluorescence values, one chunk has the length set in temporal_period_length\n",
        "#     temporal_slices = list(sliced(temporal, temporal_period_length))\n",
        "#     stimulus_slices = list(sliced(stimulus, temporal_period_length))\n",
        "\n",
        "#     #loop through slices and extract collapsed temporal features for each slice\n",
        "#     for temporal_slice in notebook.tqdm(range(len(temporal_slices))):\n",
        "\n",
        "#       if len(temporal_slices[temporal_slice]) == temporal_period_length:\n",
        "\n",
        "#         mean_fluorescence = np.mean(temporal_slices[temporal_slice]) #loop through frames\n",
        "#         min_fluorescence = np.min(temporal_slices[temporal_slice])\n",
        "#         max_fluorescence = np.max(temporal_slices[temporal_slice])\n",
        "\n",
        "#         mean_stimulus = np.mean(stimulus_slices[temporal_slice]) #loop through frames\n",
        "#         min_stimulus = np.min(stimulus_slices[temporal_slice])\n",
        "#         max_stimulus = np.max(stimulus_slices[temporal_slice])\n",
        "\n",
        "#         roi_features = roi_features.append({'roi_ID': roi_ID,\n",
        "#                                             'area': area,\n",
        "#                                             'center_of_mass_row': center_of_mass_row,\n",
        "#                                             'center_of_mass_column': center_of_mass_column,\n",
        "#                                             'mean_fluorescence': mean_fluorescence,\n",
        "#                                             'min_fluorescence': min_fluorescence,\n",
        "#                                             'max_fluorescence': max_fluorescence,\n",
        "#                                             'mean_stimulus_demo': mean_stimulus,\n",
        "#                                             'min_stimulus_demo': min_stimulus,\n",
        "#                                             'max_stimulus_demo': max_stimulus,\n",
        "#                                             'label': label}, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "KzABYxcO3gqB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# roi_features.sample(10)"
      ],
      "metadata": {
        "id": "XfZmgmEJLF31"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(roi_features)"
      ],
      "metadata": {
        "id": "8fprdqVI6FEZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# close the .h5 files\n",
        "results_file.close()\n",
        "stimulus_file.close()"
      ],
      "metadata": {
        "id": "ATuOewJfL_G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the features - still needs validation\n",
        "#manually set the filepath along with the number of frames in the window used\n",
        "roi_features.to_csv('/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Extracted_Features/210815_0_1_label_mc_mix1_syt_features_1Frame_demo.csv')"
      ],
      "metadata": {
        "id": "bo1Ee4TKz30N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oFce_ptX0gW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}