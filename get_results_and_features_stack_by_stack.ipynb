{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_results_and_features_stack_by_stack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenneal/capstone-visual-neuroscience/blob/Lauren/get_results_and_features_stack_by_stack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response and Stimulus"
      ],
      "metadata": {
        "id": "f9gUoDRpDnn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#imports\n",
        "!pip install hdf5storage\n",
        "import hdf5storage \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from tqdm import notebook\n",
        "from more_itertools import sliced\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFsKVY1z-HyU",
        "outputId": "56476884-541a-4606-eaa4-67b5caf94128"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: hdf5storage in /usr/local/lib/python3.7/dist-packages (0.1.18)\n",
            "Requirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# declare the movie we're extracting in two parts, the date and fly index, and the mix description\n",
        "#we'll add the stack index in between when we extract the results\n",
        "date_fly = '210815_0_'\n",
        "movie_info = '_20220213T070259' # it looks like now carl is using more of a movie ID than description"
      ],
      "metadata": {
        "id": "sglEN4UIS5dG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DOO3m2Ct7eT6"
      },
      "outputs": [],
      "source": [
        "#This file contains the response and stimulus data for all stacks of this movie\n",
        "#The movie id on the end corresponds with the same stacks in the results file\n",
        "\n",
        "path = '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Stimulus_Features/' + date_fly + 'stim' + movie_info + '_.mat'\n",
        "#read file in using hdf5 structure\n",
        "results_file = hdf5storage.loadmat(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list the two main folders\n",
        "list(results_file.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_OOc7mIChoL",
        "outputId": "c856a556-9645-49ce-d2a4-2fee41ea4ec7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['resp', 'stim1', 'stim2', 'stim3']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the response and stimulus are now in a 1x(number of stacks) matrix\n",
        "#Note that some stacks were split into two shorter stacks where Carl had to remove sections due to equipment interference (or something)\n",
        "#There might be a different number of stacks here compared to the stackRaw's as a result\n",
        "results_file['resp'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuQwuDnEjvfr",
        "outputId": "33a32474-defd-46dd-aec9-44c6ca923a5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#each stack has a (# of rois) by (# of frames) matrix holding the fluorescence trace of the rois in that stack\n",
        "for x in results_file['resp'][0]:\n",
        "  print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2XBAJbAmsZy",
        "outputId": "3353b85d-1813-46d4-dfbe-2a939d19102e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#same for the stimulus values\n",
        "for x in results_file['stim1'][0]:\n",
        "  print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27Py8oa6j0X3",
        "outputId": "d27273c5-4f10-4535-ae1b-d5675cbfbca1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n",
            "(15, 5513)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spatial footprints\n",
        "\n",
        "### IMPORTANT! If Carl has split any of the stacks for the response and stimulus features, we need to go into the 'results' folder and make a copy of that stack's caiman results so that the number of spatial result files matches the number of stacks\n",
        "\n",
        "### This is not an elegant solution, but it works"
      ],
      "metadata": {
        "id": "6Vf-1jMcXd4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter the files in the results folder down to the h5 files that match this movie, then reconstruct the paths\n",
        "import os\n",
        "root = '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/'\n",
        "spatial_files = os.listdir(root)\n",
        "spatial_files = [s for s in spatial_files if date_fly in s and '.h5' in s]\n",
        "spatial_filepaths = [root + s for s in spatial_files]\n",
        "spatial_filepaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La_mLJiEqdGv",
        "outputId": "25d91a53-f03e-46d6-c8aa-aae58accb3dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_10_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_1_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_2_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_3_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_4_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_5_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_6_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_7_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_8_stackRaw_mc_mix1_syt_result_20220308T134319.h5',\n",
              " '/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/210815_0_9_stackRaw_mc_mix1_syt_result_20220308T134319.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to order the paths by the stack number, put them in a pandas df, extract the stack number from the name, and sort by the number\n",
        "spatial_files_df = pd.DataFrame({\n",
        "    'filename': spatial_files,\n",
        "    'filepath': spatial_filepaths\n",
        "})\n",
        "\n",
        "#The filename starts with the date_flyIndex_stackIndex, so we split by \"_\" and take the 3rd segment (index 2)\n",
        "spatial_files_df['stack_number'] = spatial_files_df['filename'].str.split('_', expand=True)[2].astype(int)\n",
        "\n",
        "#sort by stack number to align the spatial files with the order of the stacks in the response and stimulus files\n",
        "spatial_files_df = spatial_files_df.sort_values('stack_number', ascending=True)\n",
        "spatial_files_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "ooKX1spEhP9l",
        "outputId": "4cd1fcba-1f19-4728-8112-a9fe3d85ee48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-316cef92-311b-498a-ad8a-69697d8cad58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepath</th>\n",
              "      <th>stack_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>210815_0_1_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>210815_0_2_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>210815_0_3_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>210815_0_4_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>210815_0_5_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>210815_0_6_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>210815_0_7_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>210815_0_8_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>210815_0_9_stackRaw_mc_mix1_syt_result_2022030...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>210815_0_10_stackRaw_mc_mix1_syt_result_202203...</td>\n",
              "      <td>/content/drive/MyDrive/DS6011_Capstone_VisualN...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-316cef92-311b-498a-ad8a-69697d8cad58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-316cef92-311b-498a-ad8a-69697d8cad58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-316cef92-311b-498a-ad8a-69697d8cad58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            filename  \\\n",
              "1  210815_0_1_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "2  210815_0_2_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "3  210815_0_3_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "4  210815_0_4_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "5  210815_0_5_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "6  210815_0_6_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "7  210815_0_7_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "8  210815_0_8_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "9  210815_0_9_stackRaw_mc_mix1_syt_result_2022030...   \n",
              "0  210815_0_10_stackRaw_mc_mix1_syt_result_202203...   \n",
              "\n",
              "                                            filepath  stack_number  \n",
              "1  /content/drive/MyDrive/DS6011_Capstone_VisualN...             1  \n",
              "2  /content/drive/MyDrive/DS6011_Capstone_VisualN...             2  \n",
              "3  /content/drive/MyDrive/DS6011_Capstone_VisualN...             3  \n",
              "4  /content/drive/MyDrive/DS6011_Capstone_VisualN...             4  \n",
              "5  /content/drive/MyDrive/DS6011_Capstone_VisualN...             5  \n",
              "6  /content/drive/MyDrive/DS6011_Capstone_VisualN...             6  \n",
              "7  /content/drive/MyDrive/DS6011_Capstone_VisualN...             7  \n",
              "8  /content/drive/MyDrive/DS6011_Capstone_VisualN...             8  \n",
              "9  /content/drive/MyDrive/DS6011_Capstone_VisualN...             9  \n",
              "0  /content/drive/MyDrive/DS6011_Capstone_VisualN...            10  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test that we can access each spatial file by printing the shape of the first roi mask in each file\n",
        "for x in spatial_files_df['filepath']:\n",
        "  with h5py.File(x, 'r') as file:\n",
        "    print(file['spatial'][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brH61k4LKdCE",
        "outputId": "aa564b50-1a34-48ec-bce2-4a8abef8ae15"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32768,)\n",
            "(32768,)\n",
            "(32768,)\n",
            "(32768,)\n",
            "(32768,)\n",
            "(32768,)\n",
            "(32768,)\n",
            "(32768,)\n",
            "(32768,)\n",
            "(32768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load all of the spatial matrices into memory for faster looping later - dictionary for now\n",
        "spatial_matrices = {}\n",
        "for stack_number in range(len(spatial_files_df)):\n",
        "  with h5py.File(spatial_files_df['filepath'][stack_number], 'r') as file:\n",
        "      spatial_matrices[stack_number] = file['spatial'][()].astype(bool).astype(int) #convert values to integer 0/1 representation of footprint"
      ],
      "metadata": {
        "id": "lFARzAh-sErR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#double check the shape of the first stack's matrix - should be (# of rois) by (# of pixels)\n",
        "spatial_matrices[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWxOtsj6sB1s",
        "outputId": "b35f1781-d09e-486c-fe6c-cb573cdf0029"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 32768)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell type labels"
      ],
      "metadata": {
        "id": "t2wTh-GKn498"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "label_csv = pd.read_csv('/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Results/' + date_fly + 'label' + movie_info + '_.csv')\n",
        "#Add a column that converts the index (0-index) to the roi number (1-index)\n",
        "label_csv['roi_number'] = label_csv['index'] + 1\n",
        "label_csv"
      ],
      "metadata": {
        "id": "Xph1uKaOn7xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stimulus Data read and exploration"
      ],
      "metadata": {
        "id": "Ul8bF6rPq6-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stimulus_file = h5py.File(stimulus_path, 'r')\n",
        "# stimulus_file['stimulus'].shape"
      ],
      "metadata": {
        "id": "NwzJrZOvq-mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #plot the stimulus for the first roi for the first 200 frames\n",
        "# #note that the matrix shape is flipped compared to the results matrices\n",
        "# #need to access index zero with [:,0] rather than [0]\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.plot(stimulus_file['stimulus'][:][:,0])"
      ],
      "metadata": {
        "id": "unVmi1eTugIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the first roi of the first stack\n",
        "dims = [128, 256]\n",
        "\n",
        "plt.imshow(np.reshape(spatial_matrices[0][0], dims, order=\"F\"))"
      ],
      "metadata": {
        "id": "t16V6DX8kUPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize temporal traces - first roi\n",
        "#indexing to the response subfolder, then into the array of stacks, then into the first stack, then into the first roi\n",
        "temporal = results_file['resp'][0][0][0]\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(temporal)"
      ],
      "metadata": {
        "id": "9y2WO04ILSdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize stimulus traces - first roi\n",
        "#indexing to the response subfolder, then into the array of stacks, then into the first stack, then into the first roi\n",
        "temporal = results_file['stim1'][0][0][0]\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(temporal)"
      ],
      "metadata": {
        "id": "-se1Nwh3Y9Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract features from each roi in the file"
      ],
      "metadata": {
        "id": "ZwpFrkE3Mgzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTANT\n",
        "#Set the time period in frames that we want to consider here\n",
        "#If 1, then we're doing no temporal collapsing, just taking the fluorescence / stimulus\n",
        "#if >1, then we return the mean, min, max fluorescence over chunks of that length\n",
        "\n",
        "temporal_period_length = 20\n",
        "\n",
        "#Calculate the number of stacks and the number of rois to loop through\n",
        "num_stacks = len(results_file['resp'][0])\n",
        "num_rois = len(results_file['resp'][0][0])\n",
        "print(f\"Extracting raw features for {num_rois} rois across {num_stacks} stacks\")"
      ],
      "metadata": {
        "id": "-3eBW_xpMi2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Out Raw Data\n"
      ],
      "metadata": {
        "id": "Aw_5MPzN0BbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = list(results_file.keys())\n",
        "keys"
      ],
      "metadata": {
        "id": "DK24L2hHyvcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure the shapes of each key match\n",
        "for l in keys:\n",
        "  print(results_file[l].shape)"
      ],
      "metadata": {
        "id": "NKwJbBxk0Pj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check that all data is the same size for each stack\n",
        "for l in keys:\n",
        "  print(l)\n",
        "  for s in range(0,results_file[l].shape[1]): # loop through number of stacks\n",
        "    print(results_file[l][0,s].shape) # prints shape of each stack\n",
        "  print('----------')"
      ],
      "metadata": {
        "id": "O8tFotKq0OO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is just a reference to understand the path through the object\n",
        "results_file[keys[0]][0,1][0].shape # first category, first stack, first roi, all the frames"
      ],
      "metadata": {
        "id": "Teq-xDdR0cVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = label_csv.drop(columns=['stack','index'])\n",
        "test_labels"
      ],
      "metadata": {
        "id": "4bala8grNsyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile stimulus and labels into one dataframe"
      ],
      "metadata": {
        "id": "zKnwmO1wKtOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile into df\n",
        "\n",
        "# save number of frames\n",
        "num_frames = results_file[keys[0]][0,1][0].shape[0]\n",
        "\n",
        "# get number of stacks\n",
        "num_stacks = results_file[keys[0]].shape[1]\n",
        "\n",
        "# get number of rois\n",
        "num_rois = results_file[keys[0]][0,0].shape[0]\n",
        "# -------------------------------------\n",
        "\n",
        "\n",
        "# first create a table with stack, index, label, roi_number, and frame number to hold all the data\n",
        "# create a df with a row for every frame\n",
        "raw_data = pd.DataFrame({'frame': np.array(range(0,num_frames))})\n",
        "\n",
        "# we will use the label_csv file to label all our data\n",
        "# ASSUMPTION the labels are only given for the first stack, I'm assuming this is consistent for all the stacks in this group\n",
        "# if the above is correct we will just multiply by 10.\n",
        "# THIS WILL NEED TO CHANGE WHEN WE HAVE MULTIPLE VIDEOS !!!!!!!\n",
        "full_labels = label_csv.drop(columns=['stack','index'])\n",
        "spatials = spatial_files_df.drop(columns='filepath')\n",
        "full_labels = spatials.merge(full_labels, how='cross')\n",
        "\n",
        "\n",
        "# use a cross merge to get the cross product for this table and the full_labels\n",
        "# this will give us a row for every frame for every roi in every stack\n",
        "raw_data = full_labels.merge(raw_data, how='cross').rename(columns={'stack_number':'stack','roi_number':'roi'})\n",
        "raw_data = raw_data.set_index(['filename','stack','label','roi','frame'])\n",
        "raw_data\n",
        "\n",
        "# note that frames start at 0 and roi's start at 1"
      ],
      "metadata": {
        "id": "Hw5devlb0cKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw_data.groupby('filename').count()"
      ],
      "metadata": {
        "id": "uB6Pj-jvJIK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine all stimulus data into one dataframe\n",
        "import copy\n",
        "\n",
        "stim_data = copy.deepcopy(results_file)\n",
        "col = ['stack','roi', 'frame', 'l_label', 'stim_data']\n",
        "\n",
        "# dataframe for stimulus data\n",
        "s_df = pd.DataFrame(columns=col)\n",
        "for l in keys:\n",
        "  # flat_list = []\n",
        "\n",
        "  # loop through all the stacks\n",
        "  for s in range(0,num_stacks):\n",
        "    # s_df = pd.DataFrame(columns=['stack','roi','resp','stim1','stim2','stim3'])\n",
        "    # for r in range(0,num_rois):\n",
        "\n",
        "    # create a 1D array for each column in df\n",
        "    stim_data[l][0,s] = stim_data[l][0,s].reshape((num_rois * num_frames))\n",
        "    stack = np.array([s + 1] * num_rois * num_frames)\n",
        "    roi = np.array([[r+1] * num_frames for r in range(0,num_rois)]).flatten()\n",
        "    frame_ind = np.array([list(range(0,num_frames)) * num_rois]).flatten()\n",
        "    l_label = np.array([l] * num_rois * num_frames)\n",
        "\n",
        "    # combine into 4D array\n",
        "    data_array = np.stack((stack, roi, frame_ind, l_label, stim_data[l][0,s]), axis=1)\n",
        "    \n",
        "    # combine into df\n",
        "    s_df = s_df.append(pd.DataFrame(columns=col, data=data_array)).astype({'stack': 'int32','roi': 'int32','frame': 'int32'})\n",
        "\n",
        "# s_df = s_df.pivot(columns=['stack','roi','stim_data'], values='l_label') # this crashes (out of ram)\n",
        "s_df"
      ],
      "metadata": {
        "id": "Lkv9A5blkLBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine stimulus data with raw data\n",
        "raw_data = raw_data.reset_index()\n",
        "for l in keys:\n",
        "  raw_data = raw_data.merge(s_df[s_df.l_label == l],how='right',left_on=['stack','roi','frame'], right_on=['stack','roi','frame'])\n",
        "  # name column after stimulus type\n",
        "  raw_data = raw_data.rename(columns={'stim_data': l})\n",
        "\n",
        "  # after adding to raw_data, drop data to save memory\n",
        "  s_df = s_df[s_df.l_label != l]\n",
        "\n",
        "  raw_data = raw_data.drop(columns=['l_label'])\n",
        "\n",
        "raw_data# = raw_data.drop(['stack','roi'])"
      ],
      "metadata": {
        "id": "VLV6qqczFyEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.to_csv('/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Extracted_Features/' + \\\n",
        "                      date_fly + movie_info  + 'RAW_stimulus_data.csv')"
      ],
      "metadata": {
        "id": "Md9AR3Uq8d31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MsAzSN5hqiMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rYo9x5ESqiO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## !! need to decide how to handle indexing for stacks that have been split. Right now this treats the split as two different stacks and we end up with more stacks than originally recorded ( 10 original stacks, one was split, now we have 11)"
      ],
      "metadata": {
        "id": "wobb6u6apDC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dims = [128,256]\n",
        "\n",
        "#loop through the stacks\n",
        "for stack_index in notebook.tqdm(range(num_stacks), desc='stack', position=0):\n",
        "\n",
        "  #open the corresponding spatial file and grab the spatial matrix\n",
        "  spatial_matrix = spatial_matrices[stack_index]\n",
        "  \n",
        "  #grab the corresponding response matrix from the results file\n",
        "  response_matrix = results_file['resp'][0][stack_index]\n",
        "\n",
        "  #grab the corresponding stimulus 1 matrix\n",
        "  stim1_matrix = results_file['stim1'][0][stack_index]\n",
        "  \n",
        "  #set up different dataframes depending on if we're collpsing temporal features or not\n",
        "  if temporal_period_length == 1:\n",
        "\n",
        "    roi_features = pd.DataFrame(columns =['roi_ID',\n",
        "                                        'area',\n",
        "                                        'center_of_mass_row',\n",
        "                                        'center_of_mass_column',\n",
        "                                        'resp',\n",
        "                                        'stim1',\n",
        "                                        'label',\n",
        "                                        'frame_number'])\n",
        "    \n",
        "  else:\n",
        "    roi_features = pd.DataFrame(columns =['roi_ID',\n",
        "                                      'area',\n",
        "                                      'center_of_mass_row',\n",
        "                                      'center_of_mass_column',\n",
        "                                      'mean_resp',\n",
        "                                      'min_resp',\n",
        "                                      'max_resp',\n",
        "                                      'mean_stim1',\n",
        "                                      'min_stim1',\n",
        "                                      'max_stim1',\n",
        "                                      'label',\n",
        "                                      'start_frame_number'])\n",
        "\n",
        "  #loop through rois in each file and extract features\n",
        "  for roi_index in notebook.tqdm(range(num_rois), desc='roi', position=1, leave=False):\n",
        "\n",
        "    roi_spatial = spatial_matrix[roi_index] #spatial footprint of the x'th roi\n",
        "    roi_response = response_matrix[roi_index] #temporal trace of the x'th roi\n",
        "    roi_stim1 = stim1_matrix[roi_index] #stim1 feature for the x'th roi\n",
        "    roi_label = label_csv['label'][roi_index] #cell type label of the x'th roi\n",
        "    #comcatenated ID for the roi - date, fly index, stack number, roi index, mix\n",
        "    roi_ID = date_fly + str(stack_index + 1) + \"_\" + str(roi_index) + movie_info \n",
        "\n",
        "    #calculate spatial measures for this roi\n",
        "    area = np.sum(roi_spatial)\n",
        "    spatial_img = np.reshape(roi_spatial, dims, order=\"F\")\n",
        "    center_of_mass_row, center_of_mass_column = ndimage.center_of_mass(spatial_img)\n",
        "    \n",
        "    #If one sample is one frame, no temporal slicing necessary\n",
        "    if temporal_period_length == 1:\n",
        "\n",
        "      #loop through all frames in the stack for both stimulus and response\n",
        "      for frame in range(len(roi_response)):\n",
        "\n",
        "        response = roi_response[frame] #loop through frames\n",
        "        stim1 = roi_stim1[frame] #and loop through stimulus\n",
        "\n",
        "        roi_features = roi_features.append({'roi_ID': roi_ID,\n",
        "                                            'area': area,\n",
        "                                            'center_of_mass_row': center_of_mass_row,\n",
        "                                            'center_of_mass_column': center_of_mass_column,\n",
        "                                            'resp': response,\n",
        "                                            'stim1': stim1,\n",
        "                                            'label': roi_label,\n",
        "                                            'frame_number': frame}, ignore_index=True)\n",
        "        \n",
        "    else:\n",
        "\n",
        "      #list of lists containing the sliced up fluorescence values, one chunk has the length set in temporal_period_length\n",
        "      response_slices = list(sliced(roi_response, temporal_period_length))\n",
        "      stim1_slices = list(sliced(roi_stim1, temporal_period_length))\n",
        "\n",
        "      #loop through slices and extract collapsed temporal features for each slice\n",
        "      for temporal_slice in notebook.tqdm(range(len(response_slices)), desc='frame slices', position=2, leave=False):\n",
        "\n",
        "        #check if we're at the end of a stack by checking how many frames are in the chunk\n",
        "        #if the length of this chunk is the full length we expect, continue\n",
        "        if len(response_slices[temporal_slice]) == temporal_period_length:\n",
        "\n",
        "          start_frame_number = temporal_period_length * temporal_slice\n",
        "\n",
        "          mean_resp = np.mean(response_slices[temporal_slice]) #loop through frames\n",
        "          min_resp = np.min(response_slices[temporal_slice])\n",
        "          max_resp = np.max(response_slices[temporal_slice])\n",
        "\n",
        "          mean_stim1 = np.mean(stim1_slices[temporal_slice]) #loop through frames\n",
        "          min_stim1 = np.min(stim1_slices[temporal_slice])\n",
        "          max_stim1 = np.max(stim1_slices[temporal_slice])\n",
        "\n",
        "          roi_features = roi_features.append({'roi_ID': roi_ID,\n",
        "                                              'area': area,\n",
        "                                              'center_of_mass_row': center_of_mass_row,\n",
        "                                              'center_of_mass_column': center_of_mass_column,\n",
        "                                              'mean_resp': mean_resp,\n",
        "                                              'min_resp': min_resp,\n",
        "                                              'max_resp': max_resp,\n",
        "                                              'mean_stim1': mean_stim1,\n",
        "                                              'min_stim1': min_stim1,\n",
        "                                              'max_stim1': max_stim1,\n",
        "                                              'label': roi_label,\n",
        "                                              'start_frame_number': start_frame_number}, ignore_index=True)\n",
        "          \n",
        "\n",
        "  print(f\"saving {len(roi_features)} records to {'/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Extracted_Features/' + \\\n",
        "                      date_fly + str(stack_index +1) + movie_info + str(temporal_period_length)  + 'frameWindow_rawExtract.csv'}\")  \n",
        "        \n",
        "  #save the features - uses the file info declared at the top, , the stack number, and the temporal window\n",
        "  roi_features.to_csv('/content/drive/MyDrive/DS6011_Capstone_VisualNeuroscience/Seeded_CNMF/Extracted_Features/' + \\\n",
        "                      date_fly + str(stack_index +1) + movie_info + str(temporal_period_length)  + 'frameWindow_rawExtract.csv')"
      ],
      "metadata": {
        "id": "KzABYxcO3gqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oFce_ptX0gW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}